%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[dvipsnames,format=sigconf,anonymous=true,review=true]{acmart}
	
\usepackage{soul}
\usepackage{fixme}

\usepackage{amsmath}
 % \usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{tikz,pgfplots,pgfplotstable}
\pgfplotsset{scaled x ticks = false}

\fxsetup{status=draft} % <====== add this line
\newtheorem{definition}{Definition}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
%\setcopyright{acmcopyright}
%\copyrightyear{2023}
%\acmYear{2023}


%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[GECCO '23]{Genetic Evolutionary Computation}{2023}{Lisbon, Portugal}
\acmBooktitle{GECCO '23: xx, xx, xx}
%\acmPrice{15.00}
\acmISBN{xxxxx}

\acmDOI{xxxx}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{VNS with GA-based parameter tuning for solving the $k$-domination problem}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Milan Predojević}
 
\email{milan.predojevic@pmf.unibl.org}
\orcid{xxxx-xxxx-xxxx}
\author{M.P.}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
  \institution{Faculty of Sciences and Mathematics, University of Banja Luka}
  \streetaddress{Mladen Stojanovi\'c 2}
  \city{Banja Luka}
  \state{Serb Republic}
  \country{Bosnia and Herzegovina}
  \postcode{78000}
}

\author{Aleksandar Kartelj}
\author{A.K.}
\affiliation{%
  \institution{Faculty of Mathematics, Univeristy of Belgrade}
  \streetaddress{--}
  \city{Belgrade}
  \country{Serbia}}
\email{ kartelj@math.rs}

\author{Marko Djukanović}
 
\email{marko.djukanovic@pmf.unibl.org}
\orcid{xxxx-xxxx-xxxx}
\author{M.D.}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
	\institution{Faculty of Sciences and Mathematics, University of Banja Luka}
	\streetaddress{Mladen Stojanovi\'c 2}
	\city{Banja Luka}
	\state{Serb Republic}
	\country{Bosnia and Herzegovina}
	\postcode{78000}
}
 
 
 
 

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Predojevic et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
In this paper we are concerned with solving a generalized version of the well-known minimum dominating set problem, the so-called $k$-domination problem, $k \in \mathbb{N}$. This problem is about finding a minimal cardinality subset $D$ of nodes of a graph  $G=(V, E) $ such that every $v \in V$ belongs to $D$ or has at least $k$ neighbours from $D$. The $k$-domination problem has applications in distributed systems, biological networks etc. We propose a variable neighborhood search (VNS) meta-heuristic for solving the $k$-domination problem. The VNS is equipped with an efficient fitness function that allows it to consider both feasible and infeasible solutions, while appropriately penalizing infeasible solutions. The control parameters of the VNS are tuned using a genetic algorithm. The method is compared with the best known heuristic approaches from the literature: the beam search and a few greedy approaches. Experimental evaluations are performed on a real-world benchmark set whose instances represent the road networks of different cities. The VNS provided new state-of-the-art results for all the considered problem instances with $k \in {1, 2, 4}$.
  
\end{abstract}
  
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Variable neighborhood search, graph domination, genetic algorithm,  parameter tuning}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
%\begin{teaserfigure}
%  \includegraphics[width=\textwidth]{sampleteaser}
%  \caption{Seattle Mariners at Spring Training, 2010.}
%  \Description{Enjoying the baseball game from the third-base
%  seats. Ichiro Suzuki preparing to bat.}
%  \label{fig:teaser}
%\end{teaserfigure}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
A graph $G=(V,E)$ is an abstract mathematical structure 
where $V$ represents a set of elements called vertices and   a set of pairs $e = uv =(u, v)  \in E \subseteq V \times V$ called edges of $G$. In the context of this work, we deal with  simple undirected graphs which have no loops and where edges have no directions, that is $e = \{u,v\}  = uv = vu \in E$.   Graphs serve as models of many real-world problems describing relations between various objects in biology, physics, social networks,  etc.~\cite{mashaghi2004investigation,pirzada2007applications,shah2019characterizing,doi:10.1137/S0895480100375831}. One of the most prominent classes of problems that have been studied for decades from theoretical, computational and practical aspects are dominating problems on graphs~ \cite{haynes2013fundamentals}. The basic problem of this class is the \textit{domination problem}. The subset $D \subset V$ is called a \emph{domination set} iff each vertex $v\in V$ belongs to $D$ or there is at least one vertex $w\in D$ such that $uw\in E$. Finding the smallest possible dominating set $D$ of graph $G$ w.r.t.\ its cardinalty defines \emph{the minimum dominating set problem} (MDSP)~\cite{grandoni2006note}. This problem has many applications, for example, in biological networks~\cite{nacher2016minimum}, document summarization~\cite{shen2010multi}, graph mining~\cite{chalupa2018order},  etc. From algorithmic point of view, this problem is NP--hard. It is solved by many exact approaches such as branch-and-reduce algorithms~\cite{van2011exact}, an approach that uses the fundamental cut-sets of graph~\cite{karci2020new}, etc. On the other hand, heuristic approaches appear to be dominant in the literature, for example a genetic algorithm~\cite{hedar2010hybrid}, simulated annealing~\cite{hedar2012simulated}, ant-colony optimization~\cite{ho2006enhanced}, just to name a few. There are many generalizations of MDSP proposed in the literature that arise from practice: the minimum weight dominating set problem~\cite{romania2010ant}, the minimum total dominating problem~\cite{yuan2019novel}, the minimum connected dominating set problem~\cite{butenko2004new}, etc.


In the course of this work, we study the \emph{minimum k-domination problem} (MkDP)~\cite{corcoran2021heuristics}, for a fixed $k \in \mathbf{N}$.  Note that the definition for this problem is ambiguous in the literature. One variant asks for finding a minimum cardinality vertex set $ D$ such that every vertex of $G$ is within distance $k$ from some vertex in $D$~\cite{chang1983k}. 
In this paper we take the following definition from the literature.   A $k$-\emph{dominating}  set  $D$ of a graph $G$ is a subset such that every vertex does not belong to $D$ is adjacent with at least $k$ vertices in  $D$~\cite{lan2013algorithmic}. A minimum $k$--dominating set represents the optimal solution of MkDP.  NP-completeness of the $k$-domination problem is formally proven for the split graphs, %where the problem is studied from an algorithmic point of view,
 see details in the aforementioned citation. A Beam search approach to solve the MkDP is proposed by Corcoran and Gagarin   in~\cite{corcoran2021heuristics}, so-far leading heuristic approach on small-to-middle sized real-world instances. A few greedy approaches are proposed by Couture et al.~\cite{couture2006incremental}, Gagarin and Corcoran~\cite{gagarin2018multiple}, and  Gagarin et al.~\cite{gagarin2013randomized} who proposed a randomized version of a greedy algorithm. Any of the proposed methods in the literature do not scale well with the instance size increase.   
Applications of MkDP can be found in  distributed systems  ~\cite{wang2013minimising} where  a $k$-dominating set in these systems represents a set of processors such that each processor outside the set has to have at least $k$ neighbors in the set.
In this work we propose  a variable neighborhood search (VNS) meta-heuristic to solve the MkDP.    The main algorithm components of this algorithm are:
\begin{itemize}
	\item A carefully designed fitness function that evaluates solutions  including also unfeasible ones; it takes into consideration two scores ($i$) the size of dominating set and ($ii$) a measure of penalization that evaluates how far is the considered set from being a $k$--dominating. 
	\item A shaking procedure that systematically destructs feasible solutions and ensures escaping the algorithm from a local optima. It is based on swap operations. 
	\item An efficient swap--based  best-improvement local search mechanism   has been applied. It is equipped with an quick partial evaluation of the fitness function, executed in linear time.
 
\end{itemize}
Contributions of the paper are as follow.
\begin{itemize}
	\item An efficient VNS algorithm is constructed, which performs differently from  the currently dominant constructive and mainly incremental approaches from the literature.
	
	\item The control parameters of the VNS are tuned by %two kinds of tuning tools: the Grid Search algorithm~\cite{ranjan2019k} and 
	an evolutionary-based tuning tool, found as the open-source Python library~\texttt{PyGAD}~\cite{gad2021pygad}.  
	\item The configuration of VNS, obtained by the above-mentioned tuning tool, is able to achieve new state-of-the-art results concerning all small and large-sized real-world problem instances from the literature. %they are compared to the two greedy algorithms and the BS approach from the literature. 
	\item  \textsc{Vns} approach scales better with increase in the instance size than so-far leading literature approaches. 
	%\item VNS is able to quickly produce solutions of a reasonable quality which is not the case of the state-of-the-art incremental approaches from the literature.
	%\item Concerning the (five) large-sized real instances, where BS could not finish within the proposed time limit, our VNS returns  in all cases a feasible solution quickly thus showing a better anytime behaviour than the competitor approaches. (TODO: provjeriti ovo...). The proposed \textsc{Vns} scales better with the instance size increase than the other literature approaches from literature. \fxnote{Provjeriti ovo...}
\end{itemize}

\section{Notation and problem definition }
    

    Let $G=(V,E)$ be a simple undirected graph and $k \in \mathbb{N}$ is fixed. For $v\in V$, by $N(v)$ we define a set of all neighboring vertices of $v$ in graph  $G$, that is $\{w \mid uw \in E\}$. A set $D \subseteq V$ is called a $k$--dominating iff for each $v\in V \setminus D$ it holds $|N(v) \cap D| \geq k$.  The MkDP is an optimization problem that  among all $k$--dominating sets  of graph $G$  asks for finding one with a minimum cardinalty. 
    
    
    This problem can be described by using a level of coverage of neighborhoods of vertex $v$ w.r.t.\ $D$
    \begin{equation}
    	C(D, v) = \min(k, |N(v) \cap D|)
    \end{equation}
and  formulated as the following optimization problem 
\begin{align}
    \arg \max_{D \subset V } \sum_{v \in V\setminus D} C(D,v) \\
    s.t. \forall v \in V \setminus D, |N(v) \cap D| \geq k.
\end{align}
    
\emph{Search space}.    Concerning the search space of the MkDP, we relax it by the needs of our VNS. It will not only deal with feasible solutions but also unfeasible ones  which are further  penalized, see Section~\ref{sec:vns}.  In other words, any subset of the set of vertices $V$ is a solution candidate in our VNS. Thus, the size of search space is exponential, i.e. $2^{|V|}$.  Further, any solution is encoded as a set structure consisting of those vertices that belong to the solution. 
   
   
\section{The proposed algorithm}\label{sec:vns}

In this section we first give an overview over the variable neighborhood search (VNS) scheme. Then, the main details on the VNS to solve MkDP are provided: the fitness function, the shaking procedure and the efficient local search.
 
  \subsection{Variable neighborhood search}
 \emph{Variable neighborhood search} is an effective meta-heuristic approach proposed by Mladenović and Hansen~\cite{mladenovic1997variable}. The basic idea of the approach consists of systematically exchanging the neighborhoods of incumbent solution in order to escape from getting stuck into local optimum. It is a single-point search meta-heuristic, which means it tries to improve always one solution per each iteration. VNS had been shown as one of the most powerful meta-heuristic, obtaining state-of-the-art results on a wide range of problems, such as scheduling problems~\cite{fleszar2004solving}, vehicle routing problems~\cite{rezgui2019application}, median problems~\cite{herran2019variable}, etc.  
  
  The basic VNS scheme for solving the MkDP is given in Algorithm~\ref{alg:vns}.
  
     \begin{algorithm}[!t] 
  	\caption{VNS scheme for solving MkDP}\label{alg:vns}
  	\begin{algorithmic}[1]
  		\STATE \textbf{Input:} $d_{\min}$: minimum index of neighborhoods, $d_{\max}$: maximum index of neighborhoods, %neighborhood structures  $\mathcal{N}_{d_{\min}},\ldots, \mathcal{N}_{d_{\max}}$, 
  		\emph{penalty}: penalty parameter for the fitness score; \emph{prob}: probability of accepting equally good solution 
  		\STATE \textbf{Output:}   solution $s_{best}$
  		\STATE $d \gets  d_{\min}$, $d_{\max\_init} \gets d_{\max}$
  		\STATE  $s_{best} \gets \texttt{Initialize()}$ 
         
  		\WHILE{!(\texttt{TerminationCriteriaMet()})}  \label{vns:main_loop_start}
  		\STATE  $s' \gets$  $\texttt{Shaking}(\mathcal{N}_d(s_{best}))$ \hspace{0.3cm}//\,shaking phase
  		\STATE $s' \gets  \texttt{LocalSearch}(s {'})$
  		\IF{ $fitness(s') < fitness(s_{best}) \vee (fitness(s') = fitness(s_{best})\  \wedge\ r \in U_{\left[0, 1\right]} <  prob)$ } \label{line:acceptance_incumbent_cond} %AcceptanceCriterion($s_{best}, s', fitness(\cdot)$)
  	    \STATE $s _{best}\gets s'$
  	    \STATE $d \gets d_{\min}$
  	    \IF{$|s_{best}| \geq 4$}
  	 	    \STATE  $d_{max} \gets \min(d_{\max\_init}, |s_{best}|/2)$   %\texttt{UpdateNeighbor}($d$) %$d \gets d_{min}$
  	 	 \ELSE \STATE $d_{max} \gets d_{\max\_init}$ 
  	 	     
  	 	\ENDIF
  		\ELSE 
  		\STATE $d \gets d + 1$ \hspace{0.3cm}//\, use next (VNS) neighborhood
  		\IF{$d > d_{max}$}
  		\STATE $d\gets d_{min}$
  		\ENDIF
  		\ENDIF
  		\ENDWHILE \label{vns:main_loop_end}
  		\STATE \textbf{return} $s_{best}$
  	\end{algorithmic}
  \end{algorithm}

VNS takes as the input parameters $d_{min}, d_{max} \in \mathbb{N}$ which serve to define a sequence of the considered neighborhood structures $\mathcal{N}_{d_{min}}, \ldots, \mathcal{N}_{d_{max}}$,  \emph{penalty} as a penalty parameter involved in the fitness function, and \emph{prob} parameter which serves in accepting new incumbent solution; more about the meanings of the later two parameters will be given in the next sections. 


A solution $s'$ belongs to the neighborhood structure  $\mathcal{N}_{d}(s)$, $d=d_{\min}, \ldots,  d_{\max}$  around solution $s$ if it can be obtained from $s$ by first removing some $\min(d, |s|)$ vertices from $s$ and then adding $d$ vertices from $V$ into $s$. 
 
  Initially, the starting neighborhood $d$ is set to the smallest one, i.e. to $d_{min}$. 
  Afterwards, initial solution $s_{best}$  have been generated as explained in Section~\ref{sec:init_solution}.  
  Then, the algorithm steps into the main loop (lines \ref{vns:main_loop_start}--\ref{vns:main_loop_end}) until one of the termination criteria has met. At each iteration, the following steps are executed: %(usually time limit exceeded or number of iterations has reach
  
  \begin{itemize}
  	\item \texttt{Shaking}($\mathcal{N}_d(s_{best})$): the solutions of $d$-th neighborhood structure around solution $s_{best}$ are considered, where random solution $s'$ is picked and returned from there;
  	\item  \texttt{LocalSearch}: the chosen solution $s'$ is possibly improved by a local search procedure, as explained in Section~\ref{sec:local_search};
  	\item %\texttt{AcceptanceCriterion}($s_{best}, s', fitness(\cdot)$):  this function provides a condition when to accept a solution $s'$ for as new incumbent that is $s_{best} = s'$ which also triggers an update of $d$-value; otherwise $d$ is incrementally increased. 
  	
  	Solution $s'$ becomes a new incumbent iff it represents a feasible solution and the condition  at Line~\ref{line:acceptance_incumbent_cond} of Algorithm~\ref{alg:vns} is fulfilled. If it is fulfilled, $d$ is set back to $d_{\min}$ and 
  	$d_{max}$ is dynamically adjusted to $\min(d_{\max\_init}, |s_{best}|/2)$ if $|s_{best}|\geq4$; otherwise $d_{\max}$ is set to $d_{\max\_init}$. In this way, it is not allowed to do shaking on more than a half of the overall nodes in the solution. This adjustment lead to an improved performance than without having it.  The purpose of variable $d_{max\_init}$ is storing the initial value of the variable $d_{max}$.
  	\item  If the condition  at Line~\ref{line:acceptance_incumbent_cond}  is not fulfilled, d is incrementally increased. In case that $d> d_{max}$, $d$ is again set back to $d_{min}$.
   \end{itemize}
    
    \subsection{Initialization} \label{sec:init_solution}
      Before we enter the main loop in the \textsc{Vns}, solution $s_{best}$ is initialized to the empty solution    which is further improved by the \texttt{LocalSearch}() procedure, see details in Section~\ref{sec:local_search}. 
 
   \subsection{Fitness function}
       In order to evaluate solution $s$, the following nonlinear \emph{fitness} function is used 
       \begin{align}\label{eq:fitness}
          \emph{fitness}(s) = ( 1+ penalty \cdot |s|) \times ( 1 + violate(s))
       \end{align}
       where 
       \begin{align}
       	   violate(s) = \sum_{v \in V \setminus s}   k - C(s, v)  
       \end{align}
   Note that this function evaluates both, feasible and unfeasible solutions. 
       Motivation behind the integration of this function  in the search is threefold:
       \begin{itemize}
       	\item First, any feasible solution of size $|s|$ is favored over any unfeasible solution of the same (or a larger) cardinalty. 
       	\item Between two unfeasible solutions of the same cardinalty, one whose \emph{violate}($\cdot$) score is smaller is preferred -- the solution is intuitively easier to be recreated into a feasible one.  
       	\item Between two feasible solutions, a smaller cardinalty solution is preferred (the \emph{violate}  score in that case vanishes). 
       \end{itemize}
    % Note that a solution is structured as a set of all vertices that belong to it. 
   
   \begin{comment}

   \subsection{Acceptance criterion}
   
   Solution $s'$ becomes a new incumbent iff it represents a feasible solution and  one of the following conditions is fulfilled
   \begin{itemize}
   	\item $fitness(s') < fitness(s_{best})$ 
   	\item  $fitness(s') = fitness(s_{best})\  \wedge\ r \in U_{\left[0, 1\right]} <  prob  $, where \emph{prob}$\in$[$0,1$] is a parameter of the algorithm.
   \end{itemize}
    In the case the acceptance criterion is fulfilled, $d_{max}$ is set back to $\min(d_{max}, |s|/2)$ if $|s|\geq4$ , otherwise it remains unchanged (\texttt{UpdateNeighbor()}). The variable $d_{max\_init}$ stores the initial value of the variable $d_{max}$.
 \end{comment}   
   %\subsection{Shaking}
   % As we already mentioned, the purpose of shaking is escaping from stacking into local optima this it controls amount of diversification in \textsc{VNS} algorithm.  In case of MkDP, the shaking phase   around solution $s_{best}$ for $d$-th neighborhood is realized as follows: first $d= \min(d, |s|)$ vertices from $s_{best}$ has been removed, and  newly $d$ vertices from $V $ has been randomly added to $s_{best}$ generating solution $s'$. 
    
    
 
   \subsection{Local search}\label{sec:local_search}
  The purpose of local search (LS) is improving  solution $s'$ obtained in the shaking phase by applying a larger number of small changes on  the solution's structure. Therefore, defining  the ``small changes'' which reflects on the term LS neighboring relation, plays a crucial role in establishing an effective LS procedure.  For the MkDP,  pseudocode of the LS is given in Algorithm~\ref{alg:ls}.
  
  
  \begin{algorithm}[!t] 
  	\caption{\texttt{LocalSearch}}\label{alg:ls}
  	\begin{algorithmic}[1]
  		\STATE \textbf{Input}: a solution $s$
  		\STATE \textbf{Output}: a (possibly) improved solution
  		\STATE improved $\gets$ True
  		\STATE $best\_fit \gets fitness(s)$
  		\STATE $best\_v \gets \emptyset$
 
  		\WHILE{\emph{improved}}
  		     \STATE $improved \gets  False$
  		     \FOR{$v \in V \setminus s$}
  		          \STATE $s' \gets s \cup \{v\}$
  		          \IF{$fitness(s') < fitness(s)$}
  		              \STATE $best\_v \gets v$
  		              \STATE $best\_fit \gets fitness(s')$
  		          \ENDIF
  		     \ENDFOR
  		     \IF{\emph{improved}}
  		         \STATE $s \gets s \cup \{best\_v\}$
  		         \STATE $curr\_fit \gets best\_fit$
  		     \ENDIF

  		\ENDWHILE   		    
  		 \STATE  $improved \gets True$
  		 \WHILE{\emph{improved}}
  		   \STATE $improved \gets  False$
  		    \FOR{$v \in s$}
  		       \STATE $s' \gets \setminus \{v\}$
  		        \IF{$fitness(s') < fitness(s)$}
  		             \STATE $best\_v \gets v$
  		             \STATE $best\_fit \gets fitness(s')$
  		       \ENDIF
  		        \IF{\emph{improved}}
  		       \STATE $s \gets s \setminus \{best\_v\}$
  		       \STATE $curr\_fit \gets best\_fit$
  		       \ENDIF
  		       
  		    \ENDFOR
  		\ENDWHILE
  		\STATE return $s$
  	\end{algorithmic}
\end{algorithm}

Our LS procedure applies the best improvement strategy. At each step, it examines all vertices  out of solution $s$, and chooses the best one (if any) which contributes most to the improvement of the current fitness score; that vertex is then added to $s$. Afterwards, all options to removing a vertex from $s$ are examined and the best one is chosen and   removed from it.   The algorithm stops at the first iteration  in which no improvement in the fitness score has been detected.  We emphasize that the order of vertices  through which we iterate (Lines 8 and 23) is randomly given. 

\emph{Partial fitness evaluation}. Calculating fitness function (\ref{eq:fitness}) takes $O(|E|)$ time; its the most time consuming part is the calculation of $\emph{violate}(\cdot)$  function.   If graphs are dense, this complexity may get to  $O(n^2)$. Note that at each iteration in Algorithm~\ref{alg:ls},  fitness function evaluation is performed $|V|$ times. Thus, performing the \emph{fitness} evaluation every time from scratch is too costly. 

In order to execute \texttt{LocalSearch} procedure  efficiently, partial calculations of the \emph{fitness} function are applied. More in details, before we enter the first \texttt{while} loop, $C(s, v), \forall v \in V$, values are pre-determined (cashed) for solution $s$, in the set structure. In case of a node addition, that is  $s' = s \cup \{v\} $, we do $violate(s') = violate(s) - C(s, v)  \texttt{I}_{(k> C(s,v))}  + \sum_{w\in N(v) \cap s'} \texttt{I}_{(k+1 > C(s, w))}  $ where \texttt{I} stands for the indicator function. 
In case of a node removal, we apply a similar concept as for a node addition, that is, if $s' = s \setminus \{v\}$, then $violate(s') =  violate(s) + ( k - C(s, v)) \texttt{I}_{( k > C(s, v))} $+ $\sum_{ w \in   N(v)  \setminus s} \texttt{I}_{(k+1 \leq C(s, w)) }$. By encountering a new incumbent in \texttt{LocalSearch}, cache structure $C(s, \cdot)$ has been updated accordingly.


\section{Experimental evaluation}\label{sec:experiments}


In this section we provide the analysis of the quality of the proposed \textsc{Vns} method. In order to do so, we include the competitor heuristic approaches from the literature. To be more precise, the following four methods for MkDP are compared:  

\begin{itemize}
	\item The standard greedy method from~\cite{parekh1991analysis,gagarin2013randomized}, labelled by \textsc{SG};
	\item Greedy method from~\cite{gagarin2018multiple}, labelled by \textsc{PG};
	\item Beam search approach from~\cite{corcoran2021heuristics}, labelled by \textsc{Bs};
	\item VNS approach, as described in Section~\ref{sec:vns}, labelled by \textsc{Vns}.  
\end{itemize}


\emph{Benchmark instances}. For the comparison purposes, we consider the set of real-world benchmark set from literature. It consists of 20 small-to-middle-sized instance problems and five large-sized instance problems, introduced in~\cite{corcoran2021heuristics}. All the instances represent road networks of different cities modeled by means of network reachability graphs. Five large sized road  networks correspond to international cities as follow: Belgrade, Berlin, Boston, Dublin, and Minsk.  Characteristics of large-sized instances in terms of number of vertices and edges are given in Table~\ref{tab:big_instances_chars}.  
 
 \begin{table}
 	\caption{Large-sized instance characteristics.}
 	\label{tab:big_instances_chars}  
 	\begin{tabular}{lrr}
 		City      & $|V|$ & $|E|$ \\ \hline
 		Belgrade      & 19,586 & 7,561,185  \\ 
 		Berlin        & 29,461 & 9,944,851 \\
 	    Boston        & 44,797 & 28,164,740 \\
 	    Dublin        & 37,982 & 21,630,466 \\
 	    Minsk         & 10,487 & 1,375,618 \\ \hline
 	\end{tabular}
 \end{table}
 
 Characteristics of 20 small-sized instances can be found in~\cite{corcoran2021heuristics}. For the shake of completeness, the plots providing vertex numbers and edge numbers of the graphs of these instances is given in Figure ~\ref{fig:novertex} and Figure ~\ref{fig:noedges}.  

\pgfplotstableread{ % Read the data into a table macro
    CityName	|V|
    Manchester	1991
    Nottingham	1739
    Belfast	1700
    Leeds	1647
    Sheffield	1582
    Bristol	1569
    Leicester	1531
    Sunderland	1346
    Liverpool	1273
    Exeter	1250
    Coventry	1175
    Glasgow	1137
    Cardiff	1123
    Plymouth	1122
    Newcastle	1109
    York	1044
    Brighton	976
    Bath	910
    Southampton	796
    Oxford  479
}\testdata


\begin{figure}
	\begin{tikzpicture}
		\begin{axis}[
			legend style={legend columns=1,at={(1,1)},anchor=north east},
			xbar stacked,   % Stacked horizontal bars
			bar width=5pt,
			height=250pt,
			width=0.45\textwidth,
			ytick=data,     % Use as many tick labels as y coordinates
			yticklabels from table={\testdata}{CityName}  % Get the labels from the Label column of the \datatable
			]
            \addplot [fill=cyan!20!green!40] table [x=|V|, meta=CityName,y expr=\coordindex] {\testdata};   % "First" column against the data index
            \legend{No. vertices}
		\end{axis}
	\end{tikzpicture}
	\caption{The number of vertices in the graph for small-sized instances.}
	\label{fig:novertex}
\end{figure}

\pgfplotstableread{ % Read the data into a table macro
    CityName	|E|
    Manchester	77286
    Belfast	62617
    Leeds	56511
    Nottingham	51595
    Sheffield	50534
    Leicester	48219
    Bristol	47522
    Liverpool	42564
    Sunderland	42013
    Plymouth	35070
    Brighton	35012
    Exeter	31997
    Coventry	26689
    Newcastle	26614
    Glasgow	24323
    York	23774
    Cardiff	23057
    Southampton	19942
    Bath	18560
    Oxford	8396
}\testdata


\begin{figure}
	\begin{tikzpicture}
		\begin{axis}[
			legend style={legend columns=1,at={(1,1)},anchor=north east},
			xbar stacked,   % Stacked horizontal bars
			bar width=5pt,
			height=250pt,
			width=0.45\textwidth,
			ytick=data,     % Use as many tick labels as y coordinates
			yticklabels from table={\testdata}{CityName}  % Get the labels from the Label column of the \datatable
			]
            \addplot [fill=cyan!20!green!40] table [x=|E|, meta=CityName,y expr=\coordindex] {\testdata};   % "First" column against the data index
            \legend{No. edges}
		\end{axis}
	\end{tikzpicture}
	\caption{The number of edges in the graph for small-sized instances.}
	\label{fig:noedges}
\end{figure}
 
 
 \emph{Testing environments and applied methodology}. The experiments were conducted  on a computer with Intel Core i9-9900KF CPU @3.6GHz with a memory limit of 6GB RAM per execution, under Microsoft Windows 10 Pro OS. \textsc{Vns}  is implemented in Python 3.9. The results of \textsc{SG}, \textsc{PG} and \textsc{Bs} are taken from~\cite{corcoran2021heuristics} for the small-sized instances\footnote{These instances are obtained from the authors of the paper~\cite{corcoran2021heuristics} in the original shape as used in the paper} as reported in their experimental section. The results of the  five large-sized instances\footnote{These instances have been generated by using the python script obtained from the authors. As these  scripts use  up-to-date street networks of the five cities, the large-sized instances differ from the instances used in the original publication. } are obtained by executing the original version of \textsc{PG} from the authors. According to the same authors,  \textsc{Bs} was inefficient  on the large-sized instances due to
 the high computational complexity. Therefore, we did also not consider this algorithm into comparison for the large-size instances.  
 \textsc{PG} and \textsc{Vns} algorithms are executed ten times per each problem instance. 
 
 
  The termination criteria of the \textsc{Vns} are: ($i$) the maximal time of 30~minutes, i.e., 1800 seconds is exceeded; and ($ii$) the maximal number of iteration of 1 million has reached. We decided to let us run the complete process of the solution initialization in \textsc{Vns} (Line 3 in Algorithm~\ref{alg:vns})  and only afterwards the time--limit has been checked.  
\subsection{Parameters tuning}
   Among all competitor algorithms, the parameters of \textsc{Vns} are only a matter of tuning. The following parameters are tuned: $d_{min}, d_{max}, penalty$, and \emph{prob}.  Domains of the parameters used in the tuning are given in Table~\ref{tab:domain_tuning}.
   
    \begin{table}[ht]
    	\caption{Parameter domains of \textsc{Vns}.}  
    	\label{tab:domain_tuning}
   	\begin{tabular}{lll}
    Parameter       & Domain & Step \\ \hline
   	$d_{min}$  &  [1, 10] & 1 \\
   	$d_{max}$  & [2, 100] & 1\\
   	 $penalty$ & [0.001, 0.02]  & 0.001 \\
   	 $prob$    & [0, 1] & 0.05 \\ \hline
   	\end{tabular}
   \end{table}
   
   Concerning tuning tool, we decided to use an evolutionary--based tool \texttt{PyGAD} which run a genetic algorithm (GA).  This tool is given as an open-source Python library and can be imported directly by installing the respective package. All (20) small-sized problem instances are separately tuned for each $k\in \{1, 2, 4\}$. Thus, for each of the 60 cases, a single parameter configuration of VNS was obtained.
   \fxnote{Milan: dio oko podesavanja tuning alata -- koje instance, koliki je budet broja pustanja, isl.}
  
   Details on the obtained configurations of the \textsc{Vns} %per each small-sized instance and each $k\in \{1, 2, 4\}$ produced by \texttt{PyGAD} tool 
     can be found at \url{XXxxxx.com}
     
     We emphasize that tuning process run for each (five) large-sized instances and for each $k \in \{1,2,4\}$, performed under the default configuration parameters of GA, has been inefficient. Thus, we determined a reasonable  value of the parameters  greedily, by testing a few carefully chosen meaningful parameters configurations. Among them, the best performing configuration w.r.t. delivered average solution quality has the following values: $d_{min}=1, d_{max} = + \infty, penalty = 0.01, prob=0.5$. 

\subsection{Numerical results }
 Tables~\ref{tab:k1}--\ref{tab:k4} provide the numerical results, one per each $k \in \{1, 2,4\}$ is given. The first column gives the instance name for which the results are reported; there are 20 small-sized instances, and 5 large-sized instance (provided at the   bottom rows of each table). The next block  provide the results of \textsc{Vns} -- the best result and the average solution quality over ten runs. The third block reports on the results of the best approach from the literature on the respective instance -- the algorithm (configuration) which achieved the best result, providing the best obtained result  and average solution quality over ten runs. Note that the labels BS1, BS2 or BS4 mean  that the best results are achieved by the \textsc{Bs} approach  utilizing a beam width of 1,2 or 4, respectively. 
 
   The following conclusions may be drawn from the numerical results. 
   
   \begin{itemize}
   		\item  Concerning the results for $k=1$ presented in Table~\ref{tab:k1}, in case of all (20) small-sized instances, our \textsc{Vns} achieved new state-of-the-art results, which are   significantly better than that of BS4 or BS2, the best performing literature configurations. In case of the large--sized instances,   \textsc{Vns} delivered new best solutions in all cases, also significantly better than the results of \textsc{PG} approach.  
   		\item Concerning the results for $k=2$ presented in Table~\ref{tab:k2}, in case of all (20) small-sized instances the best performing approach is again our \textsc{Vns} achieving   state-of-the-art results by significantly outperforming the \textsc{Bs} approach. Relative percentage differences between average solutions qualities delivered by the later two   approaches are about 15\% in favor of   \textsc{Vns}. For the large-sized instances, similar conclusions hold: Relative percentage differences between the  delivered average solutions qualities of \textsc{Vns} and the second best \textsc{GP} approach range from  $\approx$ 5--15\% in favor of   \textsc{Vns}. 
   		\item Concerning the results for $k=4$ presented in Table~\ref{tab:k4}, in case of all (20) small-sized instances the conclusions remain similar; the best performing approach is \textsc{Vns}, in some cases outperforming the best \textsc{Bs} configuration from the  literature by more than 15\% concerning the relative difference  between the obtained average solution qualities (see, for example,  the instance \texttt{Nottingham} where \textsc{Vns} achieved the score 165 versus BS4 which achieved the score 193). For the large-sized instances, \textsc{Vns} again outperforms \textsc{PG} in all cases. 
   		\item From the above, we conclude that our \textsc{Vns} approach scales better with increase in the instance size than so-far leading incrementally-based literature approaches, such as \text{Bs} or the greedy methods. 
   		\item Concerning average times of reaching the best solution in \textsc{Vns}, these are shown in Figure~\ref{fig:timeSmall}--\ref{fig:timeBig} by means of stick plots. % In case of the small-sized instances, it is obvious that for the instance \texttt{Oxford},  the smallest instance among the others, 
   		The smaller the size of an instance, the smaller is the average time of \textsc{Vns}  to reach the best solution.  In Figure~\ref{fig:timeSmall}, one can clearly see that with the increase of $k$, the average times of reaching the best solutions are rapidly grow thus the problem gets harder to solve. In case of the large-sized instances, one can see  from  Figure~\ref{fig:timeBig} that the most time demanding instances in terms of reaching the best solution are the instances \texttt{Boston} and \texttt{Dublin}; these are indeed the largest one in terms of number of nodes/edges, see Table~\ref{tab:big_instances_chars}.  
   		Again, one can clearly see that with the increase of $k$ value, the average times of reaching the best solution significantly increase. For the hardest problem, when $k=4$, reaching the best solutions for the two largest instances demand a huge amount of time, about 10,000 seconds. %These  average times, as expected, increase also with the instance size growth. This as the result affects the number of performed \textsc{Vns} iterations which significantly decreases as more time will be needed to perform a \textsc{Vns} iteration due to the   computationally intensive local search procedure that runs in quadratic runtime w.r.t. the instance size.
   \end{itemize}
 

 
 
  \begin{table}
  	\caption{Results for k=1.}
  	\label{tab:k1}  
 	\begin{tabular}{l|rr|rlrr}
 	\hline
 	\multicolumn{1}{c}{ } & \multicolumn{2}{|c}{VNS} & \multicolumn{3}{|c}{Literature} \\
 	\hline
	City & Best & Avg. & Alg. & Best & Avg. \\ \hline
	Bath&\bf{38}&38&BS4&43&44.6\\
	Belfast&\bf{39}&39&BS4&48&50.2\\
	Brighton&\bf{21}&21&BS4&28&28.2\\
	Bristol&\bf{37}&37&BS2&46&47.4\\
	Cardiff&\bf{39}&39&BS4&48&50.6\\
	Coventry&\bf{38}&38.2&BS4&44&44.8\\
	Exeter&\bf{38}&38&BS4&50&50.6\\
	Glasgow&\bf{50}&50.2&BS4&58&59.2\\
	Leeds&\bf{40}&40&BS4&51&52.4\\
	Leicester&\bf{38}&38&BS4&51&51.5\\
	Liverpool&\bf{28}&28&BS4&38&38.4\\
	Manchester&\bf{38}&38.8&BS4&45&45.9\\
	Newcastle&\bf{44}&44&BS4&51&52.6\\
	Nottingham&\bf{44}&44&BS4&55&56.6\\
	Oxford&\bf{24}&24&BS4&27&27.9\\
	Plymouth&\bf{31}&31&BS4&39&40.3\\
	Sheffield&\bf{42}&42&BS4&51&52.5\\
	Southampton&\bf{25}&25&BS4&28&29.6\\
	Sunderland&\bf{36}&36&BS4&46&46.3\\
	York&\bf{32}&32&BS4&39&39.1\\  \hline  \hline
	Belgrade&\bf{85}&88.4&PG&103&103.4\\
	Berlin&\bf{102}&104.5&PG&125&125.9\\
	Boston&\bf{99}&101.2&PG&101&102.7\\
	Dublin&\bf{93}&99&PG&112&113.8\\
	Minsk&\bf{100}&102&PG&125&126\\
	\hline

	
 	\end{tabular}
 \end{table}

\begin{table}
	\caption{Results for $k=2$.}
	\label{tab:k2}  
	\begin{tabular}{l|rr|rlr}
		\hline
		\multicolumn{1}{c}{ } & \multicolumn{2}{|c}{VNS} & \multicolumn{3}{|c}{Literature} \\
		\hline
		City & Best & Avg. & Alg. & Best & Avg. \\ \hline
		Bath&\bf{71}&71.8&BS1&86&89\\
		Belfast&\bf{76}&76.2&BS4&96&97.6\\
		Brighton&\bf{40}&41.1&BS4&49&49.4\\
		Bristol&\bf{73}&73.7&BS4&91&94\\
		Cardiff&\bf{79}&79.4&BS4&92&95.6\\
		Coventry&\bf{73}&73.2&BS4&84&85.1\\
		Exeter&\bf{77}&77.3&BS4&94&95.7\\
		Glasgow&\bf{93}&94.2&BS4&108&110.6\\
		Leeds&\bf{79}&80.5&BS4&98&99.6\\
		Leicester&\bf{75}&75.2&BS4&93&94.1\\
		Liverpool&\bf{57}&57&BS4&71&72\\
		Manchester&\bf{77}&78.4&BS4&90&91.5\\
		Newcastle&\bf{83}&84.3&BS4&94&95.4\\
		Nottingham&\bf{84}&85.3&BS4&102&103.3\\
		Oxford&\bf{47}&47&BS4&54&54.9\\
		Plymouth&\bf{62}&62.1&BS4&73&75\\
		Sheffield&\bf{84}&84.7&BS4&97&98.9\\
		Southampton&\bf{50}&50.1&BS4&60&61.1\\
		Sunderland&\bf{73}&73.7&BS4&87&89.1\\
		York&\bf{68}&68&BS4&77&77.6\\ \hline \hline
		Belgrade&\bf{169}&172.3&PG&196&197.3\\
		Berlin&\bf{206}&207.1&PG&239&240.1\\
		Boston&\bf{181}&194.6&PG&190&191.6\\
		Dublin&\bf{181}&184.4&PG&209&211.3\\
		Minsk&\bf{197}&201.1&PG&238&240.4\\
		\hline

	\end{tabular}
\end{table}

\begin{table}
	\caption{Results for $k=4$.}
	\label{tab:k4}  
	\begin{tabular}{l|rr|rlrr}
		\hline
		\multicolumn{1}{c}{ } & \multicolumn{2}{|c}{VNS} & \multicolumn{3}{|c}{Literature} \\
		\hline
		City & Best & Avg. & Alg. & Best & Avg. \\ \hline
		Bath&\bf{139}&140.4&BS4&159&160\\
		Belfast&\bf{147}&148.5&BS4&177&179.6\\
		Brighton&\bf{78}&79.3&BS4&92&94.8\\
		Bristol&\bf{145}&146.7&BS4&175&176.4\\
		Cardiff&\bf{160}&161.9&BS4&181&183.2\\
		Coventry&\bf{150}&150.6&BS4&170&172.6\\
		Exeter&\bf{157}&158.3&BS4&181&182.3\\
		Glasgow&\bf{174}&175.4&BS4&197&199.8\\
		Leeds&\bf{152}&152.4&BS4&186&187.1\\
		Leicester&\bf{151}&152.6&BS4&175&177.7\\
		Liverpool&\bf{112}&114&BS4&132&133\\
		Manchester&\bf{154}&156.4&BS4&177&178.5\\
		Newcastle&\bf{153}&154.8&BS2&169&171.5\\
		Nottingham&\bf{165}&166.6&BS4&193&195.2\\
		Oxford&\bf{89}&89.2&BS2&99&100.8\\
		Plymouth&\bf{115}&116&BS4&135&137\\
		Sheffield&\bf{160}&161.6&BS4&180&182.2\\
		Southampton&\bf{97}&97.8&BS4&112&113.2\\
		Sunderland&\bf{142}&142.5&BS4&162&163.6\\
		York&\bf{129}&130.1&BS4&144&145.8\\ \hline \hline
		Belgrade&\bf{344}&346.3&SG&372&374.5\\
		Berlin&\bf{408}&409.2&PG&444&446.2\\
		Boston&\bf{341}&341&PG&367&368.7\\
		Dublin&\bf{363}&363&PG&388&390.2\\
		Minsk&\bf{387}&391.5&PG&454&457.6\\
		\hline

		
	\end{tabular}
\end{table}


\pgfplotstableread{ % Read the data into a table macro
	City	k1	k2	k4
	Dublin	3301.775	5190.116	10035.541
	Boston	3313.146	5707.734	9339.97
	Berlin	2943.355	3363.764	3574.488
	Belgrade	2604.035	3454.216	3441.493
	Minsk	2086.718	2864.217	3364.123
}\testdata


\begin{figure}
	\begin{tikzpicture}
		\begin{axis}[
			legend style={legend columns=1,at={(1,1)},anchor=north east},
			xbar stacked,   % Stacked horizontal bars
			bar width=5pt,
			height=110pt,
			width=0.45\textwidth,
			ytick=data,     % Use as many tick labels as y coordinates
			yticklabels from table={\testdata}{City}  % Get the labels from the Label column of the \datatable
			]
			\addplot [fill=cyan!20!green!40] table [x=k1, meta=City,y expr=\coordindex] {\testdata};   % "First" column against the data index
			\addplot [fill=cyan!60!green!20] table [x=k2, meta=City,y expr=\coordindex] {\testdata};
			\addplot [fill=cyan!10] table [x=k4, meta=City,y expr=\coordindex] {\testdata};
			\legend{k=1, k=2,k=4}
		\end{axis}
	\end{tikzpicture}
	\caption{Average times (in seconds) of finding the best solution for big cities.}
	\label{fig:timeBig}  
\end{figure}

\pgfplotstableread{ % Read the data into a table macro
	City	k1	k2	k4
	Manchester	844.078	1608.695	2584.787
	Nottingham	85.132	1125.304	1827.64
	Belfast	66.681	865.443	1800.359
	Sunderland	44.395	187.461	2464.102
	Leicester	233.02	462.418	1729.272
	Newcastle	88.577	378.578	1147.646
	Leeds	132.67	291.423	1078.052
	Liverpool	192.537	239.716	981.006
	Bristol	129.058	571.793	638.25
	Coventry	144.585	300.407	826.953
	Brighton	89.172	292.017	858.973
	Sheffield	78.21	289.042	850.464
	Plymouth	55.003	205.265	919.927
	Cardiff	41.944	181.9	679.325
	Exeter	52.443	285.106	387.588
	Bath	60.934	256.686	285.744
	Glasgow	90.929	110.067	376.057
	York	28.401	111.923	359.89
	Southampton	7.778	147.781	203.324
	Oxford	18.758	6.93	23.79
}\testdata

\begin{figure}
	\begin{tikzpicture}
		\begin{axis}[
			legend style={legend columns=1,at={(1,1)},anchor=north east},
			xbar stacked,   % Stacked horizontal bars
			bar width=5pt,
			width=0.45\textwidth,
			height=300pt,
			ytick=data,     % Use as many tick labels as y coordinates
			yticklabels from table={\testdata}{City}  % Get the labels from the Label column of the \datatable
			]
			\addplot [fill=cyan!20!green!40] table [x=k1, meta=City,y expr=\coordindex] {\testdata};   % "First" column against the data index
			\addplot [fill=cyan!60!green!20] table [x=k2, meta=City,y expr=\coordindex] {\testdata};
			\addplot [fill=cyan!10] table [x=k4, meta=City,y expr=\coordindex] {\testdata};
			\legend{k=1, k=2,k=4}
		\end{axis}
	\end{tikzpicture}
	\caption{Average times (in seconds) of finding the best solution for small cities.}
	\label{fig:timeSmall}  
\end{figure}


 
\section{Conclusions and future work}

 
 In this paper we studied the $k$-domination problem, $k \in \mathbf{N}$,  a generalized version of the prominent minimum domination problem. This problem is solved so-far by a few constructive, incremental approaches. We proposed the well-known variable neighborhood search (VNS) meta-heuristic to solve this problem. It is equipped with an effective fitness function that evaluates feasible as well as unfeasible solutions considering the two metric scores: one which evaluates how far is the solution from being feasible and the second which takes the cardinalty of   solution.  Moreover, an efficient swap-based local search procedure incorporating best-improvement strategy plays a big role by achieving feasible solutions of reasonable quality in the \textsc{Vns}.  Efficiency of our \textsc{Vns} is confirmed on the real-world benchmark set from literature by comparing it to the existing state-of-the-art approaches -- a few greedy and the beam search approach. More in details, on all 20 small-sized and 5 large-sized instances, \textsc{Vns} delivered state-of-the-art results in terms of the obtained solution quality; the relative average percentage differences mostly range from 5-15\% in favor of \textsc{Vns}. 
 
 For future work, one could consider improving the \textsc{Vns} to perform more efficiently on large-scale graphs modeling social networks; the proposed local search needs to be significantly adapted as the best-improvement strategy is hardly a viable option on huge instances, due to  its high time complexity.  We could study performances of \textsc{Vns} and other approaches more deeply for spotting their weaknesses and strengths more clear w.r.t.\  wide range of graph sizes with different densities. Comparing our \textsc{Vns} with state-of-the-art black-box exact solvers like \textsc{Cplex} or \textsc{Gurobi} is our next task to do. 
  
  \fxnote{Marko: stigao dovde!}
\section*{Acknowledgments} 
TODO
%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{gecco_poster_literature}

%%
%% If your work has an appendix, this is the place to put it.
%\appendix
 
\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
