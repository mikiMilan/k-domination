%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[dvipsnames,format=sigconf,anonymous=true,review=true]{acmart}

\usepackage{fixme}

\usepackage{amsmath}
 % \usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[T1]{fontenc}
%\usepackage{lmodern}

\fxsetup{status=draft} % <====== add this line
\newtheorem{definition}{Definition}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
%\setcopyright{acmcopyright}
%\copyrightyear{2023}
%\acmYear{2023}


%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[GECCO '23]{Genetic Evolutionary Computation}{2023}{Lisbon, Portugal}
\acmBooktitle{GECCO '23: xx, xx, xx}
%\acmPrice{15.00}
\acmISBN{xxxxx}

\acmDOI{xxxx}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{VNS with GA-based parameter tuning for solving the $k$-domination problem}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Milan Predojević}
 
\email{milan.predojevic@pmf.unibl.org}
\orcid{xxxx-xxxx-xxxx}
\author{M.P.}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
  \institution{Faculty of Sciences and Mathematics, University of Banja Luka}
  \streetaddress{Mladen Stojanovi\'c 2}
  \city{Banja Luka}
  \state{Serb Republic}
  \country{Bosnia and Herzegovina}
  \postcode{78000}
}

\author{Aleksandar Kartelj}
\author{A.K.}
\affiliation{%
  \institution{Faculty of Mathematics, Univeristy of Belgrade}
  \streetaddress{--}
  \city{Belgrade}
  \country{Serbia}}
\email{ kartelj@math.rs}

\author{Marko Djukanović}
 
\email{marko.djukanovic@pmf.unibl.org}
\orcid{xxxx-xxxx-xxxx}
\author{M.D.}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
	\institution{Faculty of Sciences and Mathematics, University of Banja Luka}
	\streetaddress{Mladen Stojanovi\'c 2}
	\city{Banja Luka}
	\state{Serb Republic}
	\country{Bosnia and Herzegovina}
	\postcode{78000}
}
 
 
 
 

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Predojevic et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
In this paper we are concerned with solving a generalized version of the well-known minimum dominating set problem, the so-called $k$-domination problem, $k \in \mathbb{N}$. This problem is about finding a minimal cardinality subset $D$ of nodes of a graph  $G=(V, E) $ such that every $v \in V$ belongs to $D$ or has at least $k$ neighbours from $D$. The $k$-domination problem has applications in distributed systems, biological networks etc. We propose a variable neighbourhood search (VNS) meta-heuristic for solving the $k$-domination problem. The VNS is equipped with an efficient fitness function that allows it to consider both feasible and infeasible solutions, while appropriately penalising infeasible solutions. The control parameters of the VNS are tuned using a genetic algorithm. The method is compared with the best known heuristic approaches from the literature: a beam search and the two greedy approaches. Experimental evaluations are performed on a real-world benchmark set whose instances represent the road networks of different cities. The VNS provided new state-of-the-art results for most of the considered instances with $k \in {1, 2, 4}$.
  
\end{abstract}
  
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{variable neighborhood search, graph domination, genetic algorithm,  parameter tuning}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
%\begin{teaserfigure}
%  \includegraphics[width=\textwidth]{sampleteaser}
%  \caption{Seattle Mariners at Spring Training, 2010.}
%  \Description{Enjoying the baseball game from the third-base
%  seats. Ichiro Suzuki preparing to bat.}
%  \label{fig:teaser}
%\end{teaserfigure}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
A graph $G=(V,E)$ is an abstract mathematical structure 
where $V$ represents a set of elements called vertices and   a set of pairs $e = uv  \in E \subseteq V \times V$ called edges of $G$. In the context of this work, we deal with  simple undirected graphs which have no loops and where edges have no directions, that is $e = \{u,v\}  = uv = vu \in E$.   Graphs serve as models of many real--world problems describing relations between objects in biology, physics, social networks,  etc.~\cite{mashaghi2004investigation,pirzada2007applications,shah2019characterizing,doi:10.1137/S0895480100375831}. One of the most prominent classes of problems that have been studied for decades from theoretical, computational and practical aspects are dominating problems on graphs~ \cite{haynes2013fundamentals}. The basic problem of this class is the \textit{domination problem}. The subset $D \subset V$ is called a domination set iff each vertex $v\in V$ belongs to $D$ or there is at least one vertex $w\in D$ such that $uw\in E$. Finding the smallest possible dominating set $D$ of graph $G$ w.r.t.\ its cardinalty defines \emph{the minimum dominating set problem} (MDSP)~\cite{grandoni2006note}. This problem has many applications, for example analysing biological networks~\cite{nacher2016minimum}, document summarization~\cite{shen2010multi}, graph mining~\cite{chalupa2018order},  etc. From algorithmic point of view, this problem is NP--hard. It is solved by many exact approaches such as branch-and-reduce algorithms~\cite{van2011exact}, an approach that uses the fundamental cut-sets of graph~\cite{karci2020new}, etc. On the other hand, heuristic approaches are dominant in the literature, for example a genetic algorithm~\cite{hedar2010hybrid}, simulated annealing~\cite{hedar2012simulated}, ant-colony optimization~\cite{ho2006enhanced} are just some among others. There are many generalizations of MDSP proposed in the literature that arise from practice: the minimum weight dominating set problem~\cite{romania2010ant}, the minimum total dominating problem~\cite{yuan2019novel}, the minimum connected dominating set problem~\cite{butenko2004new}, etc.




In the course of this work, we study the \emph{minimum k-domination problem} (MkDP)~\cite{corcoran2021heuristics} for a fixed $k \in \mathbf{N}$.  Note that the definition for this problem is ambiguous in the literature. One variant asks for finding a minimum cardinality vertex set $ D$ such that every vertex of $G$ is within distance $k$ from some vertex in $D$~\cite{chang1983k}. 
This paper considers the following definition.  A $k$-dominating set  $D$ of a graph $G$ is a subset such that every vertex does not belong to $D$ is adjacent with at least $k$ vertices in  $D$~\cite{lan2013algorithmic}. A minimum $k$--dominating set represents the optimal solution of MkDP.  NP-completeness of the k-domination problem is proven on split graphs, where the problem is studied from an algorithmic point of view, see details in the aforementioned citation. A Beam search approach to solve the MkDP is proposed by Corcoran and Gagarin   in~\cite{corcoran2021heuristics}, so-far leading heuristic approach on small-to-middle sized real--world instances. A few greedy approaches is proposed by Couture et al.~\cite{couture2006incremental}, Gagarin and Corcoran~\cite{gagarin2018multiple}, and  Gagarin et al.~\cite{gagarin2013randomized} who proposed a randomized version of a greedy algorithm. Any of the proposed methods in the literature do not scale well with the instance size increase.   
Applications of MkDP can be found in  distributed systems  ~\cite{wang2013minimising} where  a $k$-dominating set in these systems represents a set of processors such that each processor outside the set has at least $k$ neighbors in the set.
In this work we propose a meta-heuristic approach to solve the MkDP, a variable neighborhood search (VNS). The main algorithm components of the approach are:
\begin{itemize}
	\item A carefully designed fitness function that evaluates solutions  including also unfeasible ones; it takes into consideration two scores ($i$) the size of dominating set and ($ii$) a measure of penalization that evaluates how far is the considered set from being a $k$--dominating. 
	\item A shaking procedure that systematically destructs feasible solutions and ensures escaping the algorithm from a local optima.
	\item An efficient local search mechanism that try to fix unfeasible solutions into feasible ones. It is equipped witch a fast partial evaluation of the fitness function executed in linear time.
 
\end{itemize}
Contributions of the paper are as follow.
\begin{itemize}
	\item The newly proposed VNS algorithm, which the performing differs from  the currently dominant constructive approaches in the literature.
	
	
	\item The control parameters of the VNS are tuned by two kinds of tuning tools: the Grid Search algorithm~\cite{ranjan2019k} and an evolutionary-based tuning tool, an open-source Python library~\texttt{PyGAD}~\cite{gad2021pygad}.  
	\item The two settings of VNS, obtained by the above-mentioned tuning tools, are able to achieve new state-of-the-art results concerning most of the real-world instances. %they are compared to the two greedy algorithms and the BS approach from the literature. 
	\item VNS is able to quickly produce solutions of a reasonable quality which is not the case of the state-of-the-art incremental approaches from the literature.
	\item Concerning the (five) large-sized real instances, where BS could not finish within the proposed time limit, our VNS returns  in all cases a feasible solution quickly thus showing a better anytime behaviour than the competitor approaches. (TODO: provjeriti ovo...). The proposed \textsc{Vns} scales better with the instance size increase than the other literature approaches from literature. \fxnote{Provjeriti ovo...}
\end{itemize}

\section{Notation and problem definition }
    

    Let $G=(V,E)$ be a simple undirected graph and $k \in \mathbf{N}$ is fixed. For $v\in V$, by $N(v)$ we define a set of all neighboring vertices of $v$ in graph  $G$, that is $\{w \mid uw \in E\}$. A set $D \subseteq V$ is called a $k$--dominating iff for each $v\in V \setminus D$ it holds $|N(v) \cap D| \geq k$.  The MkDP is an optimization problem that asks for finding among all $k$--dominating sets of graph $G$ one with a minimum cardinalty. 
    
    
    This problem can be described by using a level of coverage of neighborhoods of vertex $v$ w.r.t.\ $D$
    \begin{equation}
    	C(D, v) = \min(k, |N(v) \cap D|)
    \end{equation}
and  formulated as the following optimization problem 
\begin{align}
    \arg \max_{D \subset V } \sum_{v \in V\setminus D} C(D,v) \\
    s.t. \forall v \in V \setminus D, |N(v) \cap D| \geq k.
\end{align}
    
\emph{Search space}.    Concerning the search space of the MkDP, we relax it by the needs of our VNS. It will not only deal with feasible solutions but also unfeasible solutions  which are  penalized, see Section~\ref{sec:vns}.  In other words, any subset of the set of vertices $V$ is a solution candidate in our VNS. Thus, the size of search space is exponential, i.e. $2^{|V|}$.  Further, any solution is encoded as a set structure of vertices that belong to solution. 
   
   
\section{The proposed algorithm}\label{sec:vns}

In this section we first give an overview over the variable neighborhood search (VNS) scheme. Then, the main details on the VNS to solve MkDP are provided: the fitness evaluation, shaking procedure and an efficient local search.
 
  \subsection{Variable neighborhood search}
 Variable neighborhood search is an effective meta-heuristic approach proposed by Mladenović and Hansen~\cite{mladenovic1997variable}. The basic idea of the approach consists of systematically exchanging the neighborhoods of incumbent solution in order to escape from getting stack into a  local optimum. It is a single-point search metaheuristic, which means it tries to improve always one solution per each iteration. VNS had been shown as one of the most powerful meta-heuristic, obtaining state-of-the-art results on a wide range of problems, such as scheduling problems~\cite{fleszar2004solving}, vehicle routing problems~\cite{rezgui2019application}, median problems~\cite{herran2019variable}, etc.  
  
  Pseudocode of the basic VNS scheme is given in Algorithm~\ref{alg:vns}.
  
     \begin{algorithm}[!t] 
  	\caption{VNS scheme}\label{alg:vns}
  	\begin{algorithmic}[1]
  		\STATE \textbf{Input:} initial solution $s_{best}$ , neighborhoods  $\mathcal{N}_{d_{\min}},\ldots, \mathcal{N}_{d_{\max}}$ 
  		\STATE \textbf{Output:} (improved) solution $s_{best}$
  		\STATE $d \gets  d_{\min}$
  		\WHILE{!(\texttt{TerminationCriteriaMet()})}
  		\STATE  $s' \gets$  $\texttt{Shaking}(\mathcal{N}_d(s_{best}))$ \hspace{0.3cm}//\,shaking phase
  		\STATE $s' \gets  \texttt{LocalSearch}(s {'})$
  		\IF{\texttt{AcceptingCriterion}($s_{best}, s', fitness(\cdot)$)}
  		\STATE $s _{best}\gets s'$
  		\STATE $d \gets d_{min}$
  		\ELSE 
  		\STATE $d \gets d + 1$ \hspace{0.3cm}//\, use next (VNS) neighborhood
  		\IF{$d > d_{max}$}
  		\STATE $d\gets d_{min}$
  		\ENDIF
  		\ENDIF
  		\ENDWHILE
  		\STATE \textbf{return} $s_{best}$
  	\end{algorithmic}
  \end{algorithm}

 VNS takes for input a solution $s_{best}$, which may be obtained as the outcome of a greedy or some randomized procedure, $d_{min}, d_{max} \in \mathbf{N}$, 
  and a set of neighborhood structures $\mathcal{N}_{d_{min}}, \ldots, \mathcal{N}_{d_{max}}$.  
  Initially, the starting neighbor $d$ is set to the smallest one, i.e. $d_{min}$. Further, the algorithm steps in the main loop (lines 4--16) until one of the termination criteria has met. At each iteration, the following steps are executed: %(usually time limit exceeded or number of iterations has reach
  
  \begin{itemize}
  	\item \texttt{Shaking}: the solutions in $d$-th neighbor of incumbent solution $s_{best}$ is considered, and a random solution $s'$ is picked from there;
  	\item  \texttt{LocalSearch}: solution $s'$ is possibly improved by a local search procedure;
  	\item \texttt{AcceptanceCriterion}($s_{best}, s', fitness(\cdot)$): this function provided a condition when to accept a solution $s'$ for as new incumbent, that is $s_{best} = s'$; in that case, $d$ is set back to $d_{min}$; otherwise $d$ is incrementally increased. 
  	\item  If $d> d_{max}$, $d$ is again set back to $d_{min}$.
   \end{itemize}
    

   \subsection{Fitness function}
       In order to evaluate solution $s$, the following nonlinear \emph{fitness} function is used 
       \begin{align}\label{eq:fitness}
          \emph{fitness}(s) = ( 1+ penalty \cdot |s|) \times ( 1 + violate(s))
       \end{align}
       where 
       \begin{align}
       	   violate(s) = \sum_{v \in V \setminus s}   k - C(s, v)  
       \end{align}
   Note that this function evaluates both, feasible and unfeasible solutions. 
       Motivation for integrating this function  in the search is threefold:
       \begin{itemize}
       	\item First, any feasible solution of size $|s|$ is preferable over any unfeasible solution of the same (or a larger) cardinalty. 
       	\item Between two unfeasible solutions of the same cardinalty, one whose \emph{violate}($\cdot$) score is smaller is preferred -- the solution is intuitively easier to be recreated into a feasible one.  
       	\item Between two feasible solutions, a smaller cardinalty solution is preferred (\emph{violate}($\cdot$) score in that case vanishes). 
       \end{itemize}
    % Note that a solution is structured as a set of all vertices that belong to it. 
   
   \subsection{Acceptance criterion}
   
   Solution $s'$ becomes a new incumbent iff one of the following conditions is fulfilled
   \begin{itemize}
   	\item $fitness(s') < fitness(s_{best})$ 
   	\item  $fitness(s') = fitness(s_{best})\  \wedge\ r \in U_{\left[0, 1\right]} <  prob  $, where \emph{prob}$\in$[$0,1$] is a parameter of the algorithm.
   \end{itemize}
   
   
   \subsection{Shaking}
    As we already mentioned, the purpose of shaking is escaping from stacking into local optima this it controls amount of diversification in \textsc{VNS} algorithm.  In case of MkDP, the shaking phase   around solution $s_{best}$ for $d$-th neighborhood is realized as follows: first $d= \min(d, |s|)$ vertices from $s_{best}$ has been removed, and  newly $d$ vertices from $V $ has been randomly added to $s_{best}$ generating solution $s'$. 
    
    
     \fxnote{TODO: Milan} 
   \subsection{Local search}
  The purpose of local search (LS) is improving  solution $s'$ obtained in the shaking phase by applying a larger number of small changes on  the solution's structure. Therefore, defining  the ``small changes'' which reflects on the term LS neighboring relation, plays a crucial role in establishing an effective LS.  For MkDP, a pseudocode of the LS is given in Algorithm~\ref{alg:ls}.
  
  
  \begin{algorithm}[!t] 
  	\caption{LocalSearch}\label{alg:ls}
  	\begin{algorithmic}[1]
  		\STATE \textbf{Input}: a solution $s$
  		\STATE \textbf{Output}: a (possibly) improved solution
  		\STATE improved $\gets$ True
  		\STATE $best\_fit \gets fitness(s)$
  		\STATE $best\_v \gets \emptyset$
 
  		\WHILE{\emph{improved}}
  		     \STATE $improved \gets  False$
  		     \FOR{$v \in V \setminus s$}
  		          \STATE $s' \gets s \cup \{v\}$
  		          \IF{$fitness(s') < fitness(s)$}
  		              \STATE $best\_v \gets v$
  		              \STATE $best\_fit \gets fitness(s')$
  		          \ENDIF
  		     \ENDFOR
  		     \IF{\emph{improved}}
  		         \STATE $s \gets s \cup \{best\_v\}$
  		         \STATE $curr\_fit \gets best\_fit$
  		     \ENDIF

  		\ENDWHILE   		    
  		 \STATE  $improved \gets True$
  		 \WHILE{\emph{improved}}
  		   \STATE $improved \gets  False$
  		    \FOR{$v \in s$}
  		       \STATE $s' \gets \setminus \{v\}$
  		        \IF{$fitness(s') < fitness(s)$}
  		             \STATE $best\_v \gets v$
  		             \STATE $best\_fit \gets fitness(s')$
  		       \ENDIF
  		        \IF{\emph{improved}}
  		       \STATE $s \gets s \setminus \{best\_v\}$
  		       \STATE $curr\_fit \gets best\_fit$
  		       \ENDIF
  		       
  		    \ENDFOR
  		\ENDWHILE
  		\STATE return $s$
  	\end{algorithmic}
\end{algorithm}

Our LS procedure applies the best improvement strategy. At each step, it examines all vertex out of solution $s$, and chooses the best one (if any) which contributes most to the fitness decrease, further being added to $s$. Afterwards, all options to removing a vertex from $s$ are examined and the best is chosen and   removed from $s$.   The algorithm stops at the first iteration  in which no improvement in the fitness score has been detected.  We mention that the order of vertices we iterate through (Lines 8 and 23) is randomly given. 

\emph{Partial fitness evaluation}. Calculating fitness function (\ref{eq:fitness}) takes $O(|E|)$ time; its the most time consuming part is the calculation of $\emph{violate}(\cdot)$  function.   If graphs are dense, this complexity may get to  $O(n^2)$. Note that at each iteration in Algorithm~\ref{alg:ls},  fitness function evaluation is performed $|V|$ times. Thus, performing the \emph{fitness} evaluation every time from scratch is too costly. 

In order to execute \texttt{LocalSearch} procedure  efficiently, partial calculations of the \emph{fitness} function are applied. More in details, before we enter the first \texttt{while} loop, $C(s, v), \forall v \in V$, values are pre-determined (cashed) for solution $s$, in the set structure. In case of a node addition, that is  $s' = s \cup \{v\} $, we do $violate(s') = violate(s) - C(s, v)  \texttt{I}_{(k> C(s,v))}  + \sum_{w\in N(v) \cap s'} \texttt{I}_{(k+1 > C(s, w))}  $ where \texttt{I} stands for the indicator function. 
In case of a node removal, we apply a similar concept as for a node addition, that is, if $s' = s \setminus \{v\}$, then $violate(s') =  violate(s) + ( k - C(s, v)) \texttt{I}_{( k > C(s, v))} $+ $\sum_{ w \in   N(v)  \setminus s} \texttt{I}_{(k+1 \leq C(s, w)) }$. By encountering a new incumbent in \texttt{LocalSearch}, cache structure $C(s, \cdot)$ has been updated accordingly.


\section{Experimental evaluation}\label{sec:experiments}


In this section we provide empirical evidence of the quality of the proposed \textsc{Vns} method. In order to do so, we include three competitor heuristic approaches from the literature. To me more precise, the following four methods for MkDP are compared:  

\begin{itemize}
	\item The standard greedy method from~\cite{parekh1991analysis,gagarin2013randomized}, labelled by \textsc{SG};
	\item Greedy method from~\cite{gagarin2018multiple}, labelled by \textsc{PG};
	\item Beam search approach from~\cite{corcoran2021heuristics}, labelled by \textsc{Bs};
	\item VNS approach, as described in Section~\ref{sec:vns}, labelled by \textsc{Vns}.  
\end{itemize}


\emph{Benchmark instances}. For the comparison purposes, we consider the set of real--world instances. It consists of 20 small-to-middle-sized instance problems and five large-sized instance problems, introduced in~\cite{corcoran2021heuristics}. All instances are  modeling road networks of different cities by means of network reachability graphs. Five large sized street networks correspond to international cities as follow: Belgrade, Berlin, Boston, Dublin, and Minsk.
 Characteristics of large-sized instances in terms of number of vertices and edges are given in Table~\ref{tab:big_instances_chars}. \fxnote{TODO: Milan}
 
 \begin{table}
 	\begin{tabular}{lcc}
 		\textbf{City}      & $|V|$ & $|E|$ \\ \hline
 		Belgrade      & XX    &   XX  \\ 
 		Berlin        & XX    &   XX \\
 	    Boston        & XX    &   XX \\
 	    Dublin        & XX    &   XX \\
 	    Minsk         & XX    &   XX \\ \hline
 	\end{tabular}
     \caption{Large-sized instance characteristics.}
          \label{tab:big_instances_chars}  
 \end{table}
 
 Characteristics of 20 small-sized instances can be found in~\cite{corcoran2021heuristics}. For the shake of completeness, the plots providing vertex numbers and edge numbers of these instances is given in Figure \fxnote{TODO: Milan} 
 \fxnote{Marko: stigao dovde!}
 
 
 \emph{Testing environments and applied methodology}. The experiments were conducted in a single-core on a computer with Intel Core i9-9900KF CPU @3.6GHz with a memory limit of 6GB RAM per execution, under Microsoft Windows 10 Pro OS. Note that \textsc{Vns}  is implemented in Python 3.9. The results of \textsc{Greedy-1}, \textsc{Greedy-2} and \textsc{Bs} are taken from~\cite{corcoran2021heuristics} for small-sized instances\footnote{These instances are obtained from the authors of~\cite{corcoran2021heuristics} in the original shape as used in the paper} as reported in their experimental section. The results of the  five large-sized instances\footnote{These instances have been generated by using the script obtained from the authors. As the script uses up-to-date street networks of the five cities, the large-sized instances differ from the instances used in the original publication. } are obtained by executing our re-implementation of \textsc{Greedy-1}, \textsc{Greedy-2}, and \textsc{Bs} algorithms. In all cases, \textsc{Greedy-1} and \textsc{Greedy-2} are run once per each problem instance, as they are deterministic. \textsc{Bs} and \textsc{Vns} are run 10 times per each problem instance.  The termination criteria of our \textsc{Vns} are: ($i$) the maximal time of 30~minutes, i.e., 1800 seconds is exceeded; and ($ii$) the maximal number of iteration of 1 million has reached. 
\subsection{Parameters tuning}
   Among the four competitor algorithms, the parameters of \textsc{Vns} are matter of tuning. The following parameters are tuned: $d_{min}, d_{max},$ and  $penalty$. Domain of these parameters used for the tuning purposes are given in Table~\ref{tab:domain_tuning}.
   
    \begin{table}[ht]
   	\begin{tabular}{lll}
    parameter       & domain & step \\ \hline
   	$d_{min}$  &  [1, 10] & 1 \\
   	$d_{max}$  & [2, 100] & 1\\
   	 $penalty$ & [0.001, 0.02]  & 0.001 \\
   	 $prob$    & [0, 1] & 0.05 \\ \hline
   	\end{tabular}
   	\caption{Parameter domains of \textsc{Vns}.}  
   	   	\label{tab:domain_tuning}
   \end{table}
   
   Concerning tuning tool, we decided to use an evolutionary--based tool \texttt{PyGAD}. This tool is an open-source Python library an can be imported directly by installing  respective package.
   \fxnote{Milan: dio oko podesavanja tuninga -- koje instance, koliki je budet broja pustanja, isl.}
   
    \texttt{GridSearch} tool has returned the following configuration setting: TODO
    
     \texttt{PyGAD} tool has returned the following configuration setting: TODO
\subsection{Numerical results }
 TODO: Marko
 
  \begin{table}
 	\begin{tabular}{l|rrr|lrr}
 	\hline
 	\multicolumn{1}{c}{ } & \multicolumn{3}{|c}{VNS} & \multicolumn{3}{|c}{Literature} \\
 	\hline
	City & Best & Avg. & T
	 & Alg. & Best & Avg. \\ \hline
	Bath&\bf{38}&38&445.5&BS4&43&44.6\\
	Belfast&\bf{39}&39&838.3&BS4&48&50.2\\
	Brighton&\bf{21}&21&463.4&BS4&28&28.2\\
	Bristol&\bf{37}&37&791.3&BS2&46&47.4\\
	Cardiff&\bf{39}&39&419.5&BS4&48&50.6\\
	Coventry&\bf{38}&38.2&438.4&BS4&170&172.6\\
	Exeter&\bf{38}&38&514.2&BS4&181&182.3\\
	Glasgow&\bf{50}&50.2&416&BS4&197&199.8\\
	Leeds&\bf{40}&40&685.6&BS4&186&187.1\\
	Leicester&\bf{38}&38&1010.4&BS4&175&177.7\\
	Liverpool&\bf{28}&28&700.5&BS4&132&133\\
	Manchester&\bf{38}&38.8&2071.7&BS4&177&178.5\\
	Newcastle&\bf{44}&44&611.7&BS2&169&171.5\\
	Nottingham&\bf{44}&44&1211&BS4&193&195.2\\
	Oxford&\bf{24}&24&63.1&BS2&99&100.8\\
	Plymouth&\bf{31}&31&707.2&BS4&135&137\\
	Sheffield&\bf{42}&42&878.2&BS4&180&182.2\\
	Southampton&\bf{25}&25&277.5&BS4&112&113.2\\
	Sunderland&\bf{36}&36&688.6&BS4&162&163.6\\
	York&\bf{32}&32&324.6&BS4&144&145.8\\ \hline \hline
	Belgrade&\bf{85}&88.7&3610.8&PG&99&100.3\\
	Berlin&\bf{102}&104.7&3609.5&SG&146&147\\
	Boston&99&101.1&3685.6&SG&\bf{71}&72.6\\
	Dublin&96&99.7&3790.3&PG&\bf{88}&90.2\\
	Minsk&\bf{100}&102.2&3602.3&SG&138&139.3\\
	
	\hline
	
 	\end{tabular}
 	\caption{Results for k=1.}
 	\label{tab:k1}  
 \end{table}

\begin{table}
	\begin{tabular}{l|rrr|lrr}
		\hline
		\multicolumn{1}{c}{ } & \multicolumn{3}{|c}{VNS} & \multicolumn{3}{|c}{Literature} \\
		\hline
		City & Best & Avg. & T & Alg. & Best & Avg. \\ \hline
		Bath&\bf{71}&71.8&634.1&BS1&86&89\\
		Belfast&\bf{76}&76.2&1675.3&BS4&96&97.6\\
		Brighton&\bf{40}&41.1&574.7&BS4&49&49.4\\
		Bristol&\bf{73}&73.7&1588.6&BS4&91&94\\
		Cardiff&\bf{79}&79.4&897&BS4&92&95.9\\
		Coventry&\bf{73}&73.2&937.9&BS4&84&85.1\\
		Exeter&\bf{77}&77.3&582.5&BS4&94&95.7\\
		Glasgow&\bf{93}&94.2&671&BS4&108&110.6\\
		Leeds&\bf{79}&80.5&815&BS4&98&99.6\\
		Leicester&\bf{75}&75.2&1056.6&BS4&93&94.1\\
		Liverpool&\bf{57}&57&1157.7&BS4&71&72\\
		Manchester&\bf{77}&78.4&3053.1&BS4&90&91.5\\
		Newcastle&\bf{83}&84.3&823.1&BS4&94&95.4\\
		Nottingham&\bf{84}&85.3&2167.1&BS4&102&103.3\\
		Oxford&\bf{47}&47&83&BS4&54&54.9\\
		Plymouth&\bf{62}&62.1&735.1&BS4&73&75\\
		Sheffield&\bf{84}&84.7&1021.5&BS4&97&98.9\\
		Southampton&\bf{50}&50.1&315.9&BS4&60&61.1\\
		Sunderland&\bf{73}&73.7&754.2&BS4&87&89.1\\
		York&\bf{68}&68&755.1&BS4&77&77.6\\ \hline \hline
		Belgrade&\bf{169}&172.3&3614.1&PG&197&197.5\\
		Berlin&\bf{206}&207.1&3611.6&PG&268&270.4\\
		Boston&181&194.6&5707.7&PG&\bf{133}&135\\
		Dublin&181&184.4&5190.1&PG&\bf{166}&166.8\\
		Minsk&\bf{197}&201.1&3602.4&PG&265&266.4\\
		
		\hline
		
	\end{tabular}
	\caption{Results for k=2.}
	\label{tab:k2}  
\end{table}

\begin{table}
	\begin{tabular}{l|rrr|lrr}
		\hline
		\multicolumn{1}{c}{ } & \multicolumn{3}{|c}{VNS} & \multicolumn{3}{|c}{Literature} \\
		\hline
		Bath&\bf{139}&140.4&434.8&BS4&159&160\\
		Belfast&\bf{147}&148.5&2843.1&BS4&177&179.6\\
		Brighton&\bf{78}&79.3&1393.7&BS4&92&94.8\\
		Bristol&\bf{145}&146.7&979&BS4&175&176.4\\
		Cardiff&\bf{160}&161.9&1285&BS4&181&183.2\\
		Coventry&\bf{150}&150.6&1394.3&BS4&170&172.6\\
		Exeter&\bf{157}&158.3&634&BS4&181&182.3\\
		Glasgow&\bf{174}&175.4&550.8&BS4&197&199.8\\
		Leeds&\bf{152}&152.4&1737.2&BS4&186&187.1\\
		Leicester&\bf{151}&152.6&2846&BS4&175&177.7\\
		Liverpool&\bf{112}&114&1673.1&BS4&132&133\\
		Manchester&\bf{154}&156.4&3302&BS4&177&178.5\\
		Newcastle&\bf{153}&154.8&2103.6&BS2&169&171.5\\
		Nottingham&\bf{165}&166.6&2718.3&BS4&193&195.2\\
		Oxford&\bf{89}&89.2&114.9&BS2&99&100.8\\
		Plymouth&\bf{115}&116&1725.7&BS4&135&137\\
		Sheffield&\bf{160}&161.6&1351.2&BS4&180&182.2\\
		Southampton&\bf{97}&97.8&653.1&BS4&112&113.2\\
		Sunderland&\bf{142}&142.5&3539.1&BS4&162&163.6\\
		York&\bf{129}&130.1&630.5&BS4&144&145.8\\ \hline \hline
		Belgrade&\bf{344}&346.3&3610.9&SG&397&400.1\\
		Berlin&\bf{408}&409.2&3612&PG&501&503.4\\
		Boston&341&341&9340&PG&\bf{255}&255.4\\
		Dublin&363&363&10035.5&PG&\bf{317}&318.5\\
		Minsk&\bf{387}&391.5&3601.6&PG&506&509.4\\
		
		\hline
		
	\end{tabular}
	\caption{Results for k=4.}
	\label{tab:k4}  
\end{table}
 
\section{Conclusions and future work}
 TODO
 
\section*{Acknowledgments} 
TODO
%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{gecco_poster_literature}

%%
%% If your work has an appendix, this is the place to put it.
%\appendix
 
\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
