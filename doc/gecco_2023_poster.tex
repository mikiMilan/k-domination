%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf]{acmart}
\usepackage{fixme}
\usepackage{amsmath}
%\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algorithmic}
\fxsetup{status=draft} % <====== add this line
\newtheorem{definition}{Definition}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
%\setcopyright{acmcopyright}
%\copyrightyear{2023}
%\acmYear{2023}


%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[GECCO '23]{Genetic Evolutionary Computation}{2023}{Lisbon, Portugal}
\acmBooktitle{GECCO '23: xx, xx, xx}
%\acmPrice{15.00}
\acmISBN{xxxxx}

\acmDOI{xxxx}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{On solving $k$-Domination problem: Variable neighborhood search algorithm and its evolutionary-based control parameters determination}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Milan Predojević}
\authornote{Both authors contributed equally to this research.}
\email{milan.predojevic@pmf.unibl.org}
\orcid{xxxx-xxxx-xxxx}
\author{M.P.}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
  \institution{Faculty of Sciences and Mathematics, University of Banja Luka}
  \streetaddress{Mladen Stojanovi\'c 2}
  \city{Banja Luka}
  \state{Serb Republic}
  \country{Bosnia and Herzegovina}
  \postcode{78000}
}

\author{Aleksandar Kartelj}
\author{A.K.}
\affiliation{%
  \institution{Faculty of Mathematics, Univeristy of Belgrade}
  \streetaddress{--}
  \city{Belgrade}
  \country{Serbia}}
\authornote{Both authors contributed equally to this research.}
\email{ kartelj@math.rs}

\author{Marko Djukanović}
 
\email{marko.djukanovic@pmf.unibl.org}
\orcid{xxxx-xxxx-xxxx}
\author{M.D.}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
	\institution{Faculty of Sciences and Mathematics, University of Banja Luka}
	\streetaddress{Mladen Stojanovi\'c 2}
	\city{Banja Luka}
	\state{Serb Republic}
	\country{Bosnia and Herzegovina}
	\postcode{78000}
}
 
 
 
 

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Predojevic et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  TODO
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%



%\ccsdesc[500]{Computer systems organization~Embedded systems}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{variable neighborhood search, graph domination, evolutionary algorithms,  hyperparameters tuning}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
%\begin{teaserfigure}
%  \includegraphics[width=\textwidth]{sampleteaser}
%  \caption{Seattle Mariners at Spring Training, 2010.}
%  \Description{Enjoying the baseball game from the third-base
%  seats. Ichiro Suzuki preparing to bat.}
%  \label{fig:teaser}
%\end{teaserfigure}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
A graph $G=(V,E)$ is an abstract mathematical structure 
where $V$ represents a set of elements called vertices and   a set of pairs $e = uv  \in E \subseteq V \times V$ called edges of $G$. In the context of this work, we deal with  simple undirected graphs which have no loops and where edges have no directions, that is $e = \{u,v\}  = uv = vu \in E$.   Graphs serve as models of many real--world problems and relations between objects in biology, physics, social networks,  etc.~\cite{mashaghi2004investigation,pirzada2007applications,shah2019characterizing,doi:10.1137/S0895480100375831}. One of the most prominent classes of problems that have been studied for decades from theoretical, computational and practical aspects are dominating problems on graphs~ \cite{haynes2013fundamentals}. The basic problem of this class is the \textit{domination problem}. The subset $D \subset V$ is called a domination set iff each vertex $v\in V$ belongs to $D$ or there is an vertex $w\in D$ such that $uw\in E$. Finding the smallest possible dominating set $D$ of graph $G$ w.r.t.\ its cardinalty defines \emph{the minimum dominating set problem} (MDSP)~\cite{grandoni2006note}. This problem has many applications, for example analysing biological networks~\cite{nacher2016minimum}, document summarization~\cite{shen2010multi}, graph mining~\cite{chalupa2018order},  etc. From algorithmic point of view, this problem is NP--hard. It is solved by many exact approaches such as branch-and-reduce algorithms~\cite{van2011exact}, an approach that uses the fundamental cut-sets of graph~\cite{karci2020new}, etc. On the other hand, heuristic approaches are also dominant, for example a genetic algorithm~\cite{hedar2010hybrid}, simulated annealing~\cite{hedar2012simulated}, ant-colony optimization~\cite{ho2006enhanced}, among others. There are many generalizations of MDSP proposed in the literature:  the minimum weight dominating set problem~\cite{romania2010ant}, the minimum total dominating problem~\cite{yuan2019novel}, the minimum connected dominating set problem~\cite{butenko2004new}, etc.




In the course of this work, we study the \emph{minimum k-domination problem} (MkDP)~\cite{corcoran2021heuristics}.  Note that the definition for this problem is ambiguous in the literature. The first variant asks for finding a minimum cardinality vertex set $ D$ such that every vertex of $G$ is within distance $k$ from some vertex in $D$~\cite{chang1983k}. 
This paper considers the following definition.  A $k$-dominating set  $D$ of a graph $G$ is a subset such that every vertex does not belong to $D$ is adjacent to at least $k$ vertices in  $D$~\cite{lan2013algorithmic}. A minimum such k--dominating set is a solution of MkDP.  NP-completeness of the k-domination problem is established on split graphs, where the problem is studied from an algorithmic point of view, see details in the aforementioned citation. A Beam search approach to solve the MkDP is proposed by Gagarin and Corcoran   in~\cite{corcoran2021heuristics}. A few greedy approaches is firstly  proposed by Couture et al.~\cite{couture2006incremental}, and by Gagarin et al.~\cite{gagarin2013randomized} who proposed a randomized algorithm. 
Applications of this specific problem can be found in  distributed systems  ~\cite{wang2013minimising} where  a $k$-dominating set in a distributed system is a set of processors such that each processor outside the set has at least $k$ neighbors in the set.

In this work we propose another meta-heuristic approach to solve the MkDP, a variable neighborhood search (VNS). The main algorithm components of the approach are:
\begin{itemize}
	\item A carefully designed fitness function that evaluates solutions  including also unfeasible ones; it takes into consideration two scores ($i$) the size of dominating set; ($ii$) a penalized measure that evaluated how far is the considered set from being a $k$--dominating. 
	\item A shaking procedure that systematically destructs feasible solutions and ensures escaping the algorithm from a local optima.
	\item An efficient local search mechanism that try to fix unfeasible solutions into feasible ones. It is equipped witch a fast partial evaluation of the fitness function in a constant time.
 
\end{itemize}
Contributions of the paper are as follow.
\begin{itemize}
	\item The parameters of the proposed VNS are tuned by two kinds of tuning tools: the Grid Search algorithm~\cite{ranjan2019k} and an evolutionary-based tuning tool \texttt{sklearn-genetic-opt}~\cite{Arenas_Gomez2022}.  
	\item The two settings of VNS, obtained by the above-mentioned tuning tools, are able to achieve new state-of-the-art results concerning the real-world instances; they are compared to the two greedy algorithms and the BS approach from the literature. 
	\item VNS is able to quickly produce solutions of a reasonable quality which is not the case of the two state-of-the-art incremental approaches from the literature.
	\item Concerning the (five) large-sized instances, where BS could not finish within the proposed time limit, our VNS delivers in all cases a feasible solution quickly thus showing a better anytime behaviour than the competitor approaches. (TODO: provjeriti ovo...)
\end{itemize}

\section{Notation and problem definition }
    

    Let $G=(V,E)$ be a simple undirected graph and $k \in \mathbf{N}$. For $v\in V$, by $N(v)$ we define a set of all neighboring vertices of $v$ in graph  $G$, that is $\{w \mid uw \in E\}$. A set $D \subseteq V$ is called a $k$--dominating iff for each $v\in V \setminus D$ it holds $|N(v) \cap D| \geq k$.  The MkDP is an optimization problem that asks for finding among all $k$--dominating sets of $G$ that of a minimum cardinalty. 
    
    
    This problem can be described by using a level of coverage of neighborhoods of vertex $v$ w.r.t.\ $D$
    \begin{equation}
    	C(D, v) = \min(k, |N(v) \cap D|)
    \end{equation}
and  formulated as the following optimization problem 
\begin{align}
    \arg \max_{D \subset V } \sum_{v \in V\setminus D} C(D,v) \\
    s.t. \forall v \in V \setminus D, |N(v) \cap D| \geq k.
\end{align}
    
\emph{Search space}.    Concerning the search space of the MkDP, we relax it by the needs of our VNS by not only searching for feasible solutions but also considering unfeasible ones which will be penalized, see Section~\ref{sec:vns}.  In other words, any subset of the set of vertices $V$ is a candidate solution in our VNS procedure. Thus, the size of search space is exponential, i.e. $2^{|V|}$.Further, a solution will be encoded as a set structure (of indices of vectors). 
   
   
\section{The proposed algorithm}\label{sec:vns}

In this section we first give an overview of the variable neighborhood search (VNS) scheme. Then, the main details on the VNS to solve MkDP are provided: the fitness evaluation, shaking procedure and local search.
 
  \subsection{Variable neighborhood search}
 Variable neighborhood search is an effective meta-heuristic approach proposed by Mladenović and Hansen~\cite{mladenovic1997variable}. The basic idea of the approach consists of systematically exchanging the neighborhoods of incumbent solution in order to escape from local optima. It is a single-point search metaheuristic, thus trying to improve always one solution per iteration. VNS had been proved as one of the most powerful meta-heuristic, delivering state-of-the-art results on a wide range of problems, such as scheduling problems~\cite{fleszar2004solving}, vehicle routing problems~\cite{rezgui2019application}, median problems~\cite{herran2019variable}, etc.  
  
  The pseudocode of the basic VNS scheme is given in Algorithm~\ref{alg:vns}.
  
     \begin{algorithm}[!t] 
  	\caption{VNS scheme}\label{alg:vns}
  	\begin{algorithmic}[1]
  		\STATE \textbf{Input:} initial solution $s_{best}$ , neighborhoods  $\mathcal{N}_{k_{\min}},\ldots, \mathcal{N}_{k_{\max}}$ 
  		\STATE \textbf{Output:} (improved) solution $s_{best}$
  		\STATE $k \gets  k_{\min}$
  		\WHILE{!(\emph{TerminationCriteriaMet()})}
  		\STATE  $s' \gets$  $\texttt{Shaking}(\mathcal{N}_k(s_{best}))$ \hspace{0.3cm}//\,shaking phase
  		\STATE $s' \gets  \texttt{LocalSearch}(s {'})$
  		\IF{$fitness(s') < fitness(s_{best})$}
  		\STATE $s _{best}\gets s'$
  		\STATE $k \gets k_{min}$
  		\ELSE 
  		\STATE $k \gets k+1$ \hspace{0.3cm}//\, use next (VNS) neighborhood
  		\IF{$k > k_{max}$}
  		\STATE $k\gets k_{min}$
  		\ENDIF
  		\ENDIF
  		\ENDWHILE
  		\STATE \textbf{return} $s_{best}$
  	\end{algorithmic}
  \end{algorithm}

 VNS takes for input a solution $s_{best}$ obtained by a greedy or some randomized procedure, $k_{min}, k_{max} \in \mathbf{N}$, 
  and a set of neighborhood structures $\mathcal{N}_{k_{min}}, \ldots, \mathcal{N}_{k_{max}}$.  
  Initially, the starting neighbor $k$ is set to the smallest one, i.e. $k_{min}$. Further, the algorithm steps in the main loop (lines 4--16) until one of the termination criteria has met. At each iteration, the following steps are executed: %(usually time limit exceeded or number of iterations has reach
  
  \begin{itemize}
  	\item \texttt{Shaking}: $k$-th neighbor of incumbent solution $s_{best}$ is considered, and a random solution $s'$ is picked from there;
  	\item  \texttt{LocalSearch}: solution $s'$ is possibly improved by a local search procedure;
  	\item If a possibly improved solution $s'$ is better than $s_{best}$, it is declared for a new incumbent, this $s_{best} = s'$, and $k$ is set back to $k_{min}$; otherwise $k$ is incrementally increased;
  	\item  If $k> k_{max}$, $k$ is again set back to $k_{min}$.
   \end{itemize}
    

   \subsection{Fitness function}
       In order to evaluate solution $s$, the following nonlinear \emph{fitness} function is used 
       \begin{align}
          \emph{fitness}(s) = ( 1+ penalty \cdot |s|) \times ( 1 + violate(s))
       \end{align}
       where 
       \begin{align}
       	   violate(s) = \sum_{v \in V \setminus s} ( k - C(s, v) ) 
       \end{align}
   Note that this function operates on both, feasible and unfeasible solutions. 
       Motivation for integrating this function  in the search is threefold:
       \begin{itemize}
       	\item First, any feasible solution of size $|s|$ is preferable over any unfeasible solution of the same cardinalty. 
       	\item Between two unfeasible solutions of the same cardinalty, the search prefers that whose violation score is smaller, thus occasionally easier to be reshaped into   feasible one.  
       	\item Between two feasible solutions, the better is the one with a smaller cardinalty. 
       \end{itemize}
   
   
   \subsection{Shaking}
    As we already mentioned, the purpose of shaking is to escape the search from stacking into   local optima. In case of MkDP, the shaking is realized as follows: \fxnote{TODO: Milan} 
   \subsection{Local search}
 

\section{Experimental evaluation}


\subsection{Parameters tuning}

\subsection{Numerical results }
 
\section{Conclusions and future work}
 TODO
 
\section*{Acknowledgments} 
TODO
%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{gecco_poster_literature}

%%
%% If your work has an appendix, this is the place to put it.
%\appendix
 
\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
