%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[dvipsnames,format=sigconf]{acmart} %,anonymous=true,review=true]{acmart}
	
\usepackage{soul}
\usepackage{fixme}

\usepackage{amsmath}
 % \usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{tikz,pgfplots,pgfplotstable}
\pgfplotsset{scaled x ticks = false}
\usepackage{comment}

 \fxsetup{status=draft} % <====== add this line
\newtheorem{definition}{Definition}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2023}
\acmYear{2023}
\setcopyright{rightsretained}
\acmConference[GECCO '23 Companion]{Genetic and Evolutionary Computation
	Conference Companion}{July 15--19, 2023}{Lisbon, Portugal}
\acmBooktitle{Genetic and Evolutionary Computation Conference Companion
	(GECCO '23 Companion), July 15--19, 2023, Lisbon,
	Portugal}\acmDOI{10.1145/3583133.3590607}
\acmISBN{979-8-4007-0120-7/23/07}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Variable neighborhood search for solving the $k$-domination problem}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Milan Predojević}
 
\email{milan.predojevic@pmf.unibl.org}
\orcid{xxxx-xxxx-xxxx}
\author{M.P.}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
  \institution{Faculty of Sciences and Mathematics, University of Banja Luka}
  \streetaddress{Mladen Stojanovi\'c 2}
  \city{Banja Luka}
  \state{Serb Republic}
  \country{Bosnia and Herzegovina}
  \postcode{78000}
}

\author{Aleksandar Kartelj}
\author{A.K.}
\email{ aleksandar.kartelj@matf.bg.ac.rs}
\affiliation{%
  \institution{Faculty of Mathematics, University of Belgrade}
  \streetaddress{Studentski trg 16}
  \city{Belgrade}
  \country{Serbia}}

\author{Marko Djukanović}
 
\email{marko.djukanovic@pmf.unibl.org}
\orcid{xxxx-xxxx-xxxx}
\author{M.Dj.}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
\affiliation{%
	\institution{Faculty of Sciences and Mathematics, University of Banja Luka}
	\streetaddress{Mladen Stojanovi\'c 2}
	\city{Banja Luka}
	\state{Serb Republic}
	\country{Bosnia and Herzegovina}
	\postcode{78000}
}
 
 
%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Predojevic et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
In this paper we {\color{red}tackle} a generalized version of the well-known minimum dominating set problem, the so-called $k$-domination problem, $k \in \mathbb{N}$. This problem is about finding a minimal cardinality subset $D$ of vertices of a graph  $G=(V, E) $ such that every $v \in V$ belongs to $D$ or has at least $k$ neighbors from $D$. The $k$-domination problem has applications in distributed systems, biological networks etc. We propose a variable neighborhood search (VNS) metaheuristic for solving the $k$-domination problem. The \textsc{Vns} is equipped with an efficient fitness function that allows it to consider both feasible and infeasible solutions, while appropriately penalizing infeasible solutions. The control parameters of the \textsc{Vns} are tuned using a grid search approach. The method is compared to the best known heuristic approaches from the literature: the beam search and several greedy approaches. Experimental evaluations are performed on a real-world benchmark set whose instances represent the road networks of different cities. The \textsc{Vns} provided new best results for all considered problem instances with $k \in \{1, 2, 4\}$.
  
\end{abstract}

\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10003752.10003809.10003716.10011136.10011797</concept_id>
	<concept_desc>Theory of computation~Optimization with randomized search heuristics</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Optimization with randomized search heuristics}
  
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Variable neighborhood search, graph domination, \textcolor{red}{metaheuristics, combinatorial optimization}}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
%\begin{teaserfigure}
%  \includegraphics[width=\textwidth]{sampleteaser}
%  \caption{Seattle Mariners at Spring Training, 2010.}
%  \Description{Enjoying the baseball game from the third-base
%  seats. Ichiro Suzuki preparing to bat.}
%  \label{fig:teaser}
%\end{teaserfigure}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
A graph $G=(V,E)$ is an abstract mathematical structure 
in which $V$ represents a set of elements called vertices (or nodes) and a set of pairs $e = uv =(u, v)  \in E \subseteq V \times V$ called edges of $G$. In this paper, we are concerned with simple undirected graphs that have no loops and where the edges have no directions, i.e., $e = \{u,v\} = uv = vu \in E$.   Graphs serve as models for many real-world problems describing relationships among various objects in biology, physics, social networks,  etc.~\cite{mashaghi2004investigation,pirzada2007applications,shah2019characterizing,doi:10.1137/S0895480100375831}. 

One of the best known classes of problems studied from theoretical, computational and practical points of view are domination problems on graphs~ \cite{haynes2013fundamentals}. The basic problem of this class is the \textit{minimum dominating set problem}. The subset $D \subset V$ is called \emph{dominating set} if each vertex $v\in V$ belongs to $D$ or there is at least one vertex $w\in D$ such that $uw\in E$. The search for the smallest possible dominating set $D$ of the graph $G$ is called \emph{the minimum dominating set problem} (MDSP)~\cite{grandoni2006note}. This problem has many applications, for example, in biological networks~\cite{nacher2016minimum}, document summarization~\cite{shen2010multi}, graph mining~\cite{chalupa2018order}, etc. From an algorithmic point of view, this problem is NP-hard. It is solved by various exact approaches, such as branch-and-reduce algorithms~\cite{van2011exact}, an approach that uses the fundamental cut-sets of the graph~\cite{karci2020new}, etc. Heuristic approaches are more common in the literature, e.g., a genetic algorithm~\cite{hedar2010hybrid}, simulated annealing~\cite{hedar2012simulated}, ant colony optimization~\cite{ho2006enhanced}, to name a few. Several generalizations of MDSP, arising from practical experience, are proposed in the literature: the minimum weight dominating set problem~\cite{romania2010ant}, the minimum total dominating set problem~\cite{yuan2019novel}, the minimum connected dominating set problem~\cite{butenko2004new}, etc.


In this paper, we study the \emph{minimum k-domination problem} (MkDP)~\cite{corcoran2021heuristics}, for a fixed $k \in \mathbf{N}$. 
The $k$-\emph{dominating} set $D$ of a graph $G$ is such a subset of $V$ that every vertex not belonging to $D$ is adjacent to at least $k$ vertices in $D$~\cite{lan2013algorithmic}. A minimum $k$-dominating set represents the optimal solution of MkDP. The NP-completeness of the $k$-domination decision problem is formally proved for the split graphs, see details in the above citation. (Note that the definition of this problem is not unique in the literature -- there is a definition where the goal is to find a minimum cardinality vertex set $D$ such that every vertex of $G$ is within distance $k$ of some vertex in $D$~\cite{chang1983k}.) 
 
Regarding previous solutions to this problem, several greedy approaches have been proposed by Couture et al.~\cite{couture2006incremental}, Gagarin et al.~\cite{gagarin2013randomized}, and Gagarin and Corcoran~\cite{gagarin2018multiple}. Recently, Corcoran and Gagarin proposed a Beam search approach~\cite{corcoran2021heuristics}, which is currently the best-performing heuristic approach for small to medium sized real-world instances. 
 
MkDP has applications in distributed systems~\cite{wang2013minimising}, where a $k$-dominating set {\color{red}represents} a set of processors such that each processor outside \textcolor{red}{this set} must have at least $k$ neighbors in the set.

We propose a variable neighborhood search (VNS) metaheuristic for solving MkDP. 
\begin{comment}
The main algorithm components of this algorithm are:
\begin{itemize}
	\item A carefully designed fitness function that evaluates solutions  including also unfeasible ones; it takes into consideration two scores ($i$) the size of dominating set and ($ii$) a measure of penalization that evaluates how far is the considered set from being a $k$--dominating. 
	\item A shaking procedure that systematically destructs feasible solutions and ensures escaping the algorithm from a local optima. It is based on swap operations. 
	\item An efficient swap--based  best-improvement local search mechanism   has been applied. It is equipped with an quick partial evaluation of the fitness function, executed in linear time.
\end{itemize}
\end{comment}
%The contributions of our work can be summarized as follows:
 {\color{red}The main contribution of our work is that the proposed \textsc{Vns}} significantly improves the state-of-the-art results for all considered problem instances, in case of $k \in \{1, 2, 4\}$.  %; ($ii$) \textsc{Vns} is able almost always quickly produce solutions of reasonable quality which is not the case for approaches previously proposed in the literature.

\section{Formal problem definition }
    
Let $G=(V,E)$ be a simple undirected graph and $k \in \mathbb{N}$ be fixed. For $v\in V$, $N(v)$ is a set of all adjacent vertices of $v$ in the graph $G$, i.e. $N(v)=\{w \mid vw \in E\}$. A set $D \subseteq V$ is called $k$-dominating set if for every $v\in V \setminus D$ holds $|N(v) \cap D| \geq k$. The MkDP is an optimization problem whose objective is to find a $k$-dominating set with minimal cardinality:

\begin{equation}
\arg \min_{D \subseteq V } |D|
  	\mbox{  s.t. } \; \forall v \in V \setminus D, |N(v) \cap D| \geq k.
\end{equation}
    
As for the search space of the MkDP, we adapt it to the needs of our VNS. Not only feasible solutions are handled, but also infeasible ones -- they are additionally penalized, see Section~\ref{sec:vns}. In other words, every subset of $V$ is a candidate solution in our VNS. Therefore, the size of the search space is $2^{|V|}$. 
%Each solution is encoded as a set structure consisting of those vertices that belong to the solution. 
   
   
\section{The proposed algorithm}\label{sec:vns}

In this section, we first give an overview of the variable neighborhood search (VNS). Then we introduce the main components of \textsc{Vns} for solving MkDP: the fitness function, the shaking procedure and the efficient local search.
 
  \subsection{Variable neighborhood search}
 \emph{Variable neighborhood search} is a single-based solution metaheuristic proposed by Mladenović and Hansen~\cite{mladenovic1997variable}. The basic idea of the approach is to systematically exchange neighborhoods of the current best solution (incumbent solution) to avoid getting stuck in a local optimum. \textsc{Vns} has proven to be one of the most powerful metaheuristic, achieving excellent results on diverse classes of problems, such as scheduling problems~\cite{fleszar2004solving}, vehicle routing problems~\cite{rezgui2019application}, median problems~\cite{herran2019variable}, etc.  
  
 The \textsc{Vns} for solving the MkDP is given in Algorithm~\ref{alg:vns}. 
 
 \textsc{Vns} generally requires at least two control parameters $d_{min}, d_{max} \in \mathbb{N}$, which define the increasing sizes of the neighborhood structures $\mathcal{N}_{d_{min}}(D), \ldots, \mathcal{N}_{d_{max}}(D)$ around given solution $D$. A solution $D'$ belongs to the neighborhood $\mathcal{N}_{d}(D)$ of the solution $D$ if it can be obtained from $D$ by removing $\min(d, |D|)$ vertices from $D$ and then adding $d$ vertices from $V \setminus D$ into $D$.
 
 The third parameter commonly used in \textsc{Vns} is $p_{move} \in [0, 1]$. This parameter corresponds to the probability of moving to a new solution if it has the same quality (fitness) as the incumbent solution. 
 Finally, the fourth control parameter \emph{penalty} is specific to MkDP. It is real-valued and is used to define the relative influence of solution feasibility and solution quality (size of $k$-dominating set) on the overall value of the fitness function (more details are given in Section~\ref{subsec:fit}).
 The return value of \textsc{Vns} is called $D_{best}$ -- it is the incumbent solution. 
  
     \begin{algorithm}[!t] 
  	\caption{\textsc{Vns} scheme for solving MkDP}\label{alg:vns}
  	\begin{algorithmic}[1]
  		\STATE \textbf{Input:} $d_{\min}$, $d_{\max}$, $p_{move}$, \emph{penalty}
  		\STATE \textbf{Output:} best found solution $D_{best}$
  		\STATE $d \gets  d_{\min}$, $d_{\max\_init} \gets d_{\max}$
  		\STATE  $D_{best} \gets \texttt{LocalSearch}(\emptyset)$ \label{vns:init}
  		\WHILE{\texttt{TerminationCriteriaNotMet()}}  \label{vns:main_loop_start}
  		\STATE  $D' \gets$  $\texttt{Shaking}(\mathcal{N}_d(D_{best}))$
  		\STATE $D'' \gets  \texttt{LocalSearch}(D')$
  		\IF{ $fitness(D'') < fitness(D_{best}) \vee (fitness(D'') = fitness(D_{best})\  \wedge\ r \in U_{\left[0, 1\right]} <  p_{move})$ } \label{line:acceptance_incumbent_cond}
  	    \STATE $D _{best}\gets D''$
  	    \STATE $d \gets d_{\min}$
  	 	\STATE  $d_{max} \gets \min(d_{\max\_init}, |D_{best}|/2)$  \label{vns:implicit_bound}
  		\ELSE 
  		\STATE $d \gets d + 1$ \hspace{0.3cm}//\, try with next neighborhood
  		\IF{$d > d_{max}$}
  		\STATE $d\gets d_{min}$
  		\ENDIF
  		\ENDIF
  		\ENDWHILE \label{vns:main_loop_end}
  		\STATE \textbf{return} $D_{best}$
  	\end{algorithmic}
  \end{algorithm}

  At the beginning, the neighborhood size $d$ is set to the smallest, i.e. to $d_{min}$. 
  The initial incumbent solution $D_{best}$ is generated by performing local search on an empty set (local search is explained in Section~\ref{sec:local_search}).  
  Then the algorithm enters the main loop (lines \ref{vns:main_loop_start}-\ref{vns:main_loop_end}). The loop is run until at least one of the termination criteria is met. At each iteration of the loop, the following steps are executed: 
  
  \begin{itemize}
  	\item \texttt{Shaking}($\mathcal{N}_d(D_{best})$) -- a solution $D'$ is selected   randomly from the set of solutions belonging to the $d$-th neighborhood structure around the solution $D_{best}$.
  	\item  \texttt{LocalSearch} -- the selected solution $D'$ may be improved by a local search procedure, as explained in Section~\ref{sec:local_search}.
  	\item The solution $D'$ becomes new incumbent if it has better fitness than the previous incumbent. Alternatively, it may become new incumbent with probability $p_{move}$ if its fitness is the same. In both cases, $d$ is reset to $d_{\min}$. The parameter $d_{max}$ is dynamically set to $\min(d_{\max\_init}, |D_{best}|/2)$ to prevent neighborhoods that are too large, i.e., neighborhoods larger than half  the incumbent size. 
  	\item  If the solution $D'$ does not become new incumbent, $d$ is increased -- this further increases diversification. If this increase leads to $d> d_{max}$, $d$ is circularly reset to $d_{min}$.
   \end{itemize}
    
\subsection{Fitness function}\label{subsec:fit}
   To evaluate solution $D$, the following   \emph{fitness} function is used:
   \begin{align}\label{eq:fitness}
      \emph{fitness}(D) = ( 1 + viols(D)) \cdot ( 1+ penalty \cdot |D|)
   \end{align}
   with   $viols(D) = \sum_{v \in V \setminus D}{k-C(D, v)},$  $C(D, v) = \min(k, |N(v) \cap D|)$.
   

It can be seen that $viols(D)$ quantifies the overall degree of solution $D$ inadmissibility, i.e., for each vertex $v$ that does not belong to a candidate dominating set $D$, $k-C(D, v)$ measures how strongly vertex $v$ locally violates the $k$-domination condition. Thus, $C(D, v)$ quantifies the opposite -- how strongly the vertex $v$ satisfies the $k$-domination condition. In particular, when vertex $v$ has $k$ or more vertex neighbors in $D$, the value of $k - \min(k, |N(v) \cap D|)$ is zero. Otherwise, $C(D, v)$ is positive and at most $k$. 

Therefore, the proposed fitness function evaluates both feasible and infeasible solutions. Since the fitness function is to be minimized, the following three observations can be made about the values of the fitness function:
\begin{itemize}
 		\item For sufficiently small values of the parameter \emph{penalty}, the feasibility of the solution is relatively preferred over the cardinality of the solution. This means that when comparing feasible and infeasible solutions, the feasible solution is favored. 
 
     	\item When comparing two infeasible solutions of the same cardinality, the \emph{less infeasible} solution is preferred, i.e. the one with the lower $viols(\cdot)$ value.  
        
        \item When comparing two feasible solutions, the one with the lower cardinality is preferred.
\end{itemize}

\subsection{Local search}\label{sec:local_search}
The goal of local search (LS) is to improve the solution $D'$ obtained in the shaking phase by applying multiple local improvements to the structure of the solution. 

\begin{comment}
    The LS tailored to MkDP is described in Algorithm~\ref{alg:ls}.

  \begin{algorithm}[!t] 
  	\caption{\texttt{LocalSearch}}\label{alg:ls}
  	\begin{algorithmic}[1]
  		\STATE \textbf{Input}: a solution $D$
  		\STATE \textbf{Output}: a (possibly) improved solution $D_{best}$
  		\STATE $D_{best} \gets D$
  		\STATE $best_{fit} \gets fitness(D_{best})$
 		\\//\, first, achieve feasibility by adding vertices
 		\STATE improved $\gets$ True
  		\WHILE{\emph{improved}}
  		     \STATE $improved \gets  False$
  		     \STATE $best_{v} \gets$ None
  		     \FOR{$v \in V \setminus D_{best}$}
  		          \STATE $D' \gets D_{best} \cup \{v\}$
  		          \IF{$new_{fit} = fitness_{fast}(D') < best_{fit}$}
  		              \STATE $best_v \gets v$
  		              \STATE $best_{fit} \gets new_{fit}$
  		              \STATE $improved \gets True$
  		          \ENDIF
  		     \ENDFOR
  		     \IF{\emph{improved}}
  		         \STATE $D_{best} \gets D_{best} \cup \{best_v\}$
  		     \ENDIF

  		\ENDWHILE   	
  		\\ //\, second, remove vertices, but keep the feasibility	    
  		 \STATE  $improved \gets True$
  		 \WHILE{\emph{improved}}
  		   \STATE $improved \gets  False$
  		    \STATE $best_{v} \gets$ None
  		    \FOR{$v \in D_{best}$}
  		       \STATE $D' \gets D_{best} \setminus \{v\}$
  		        \IF{$new_{fit} = fitness_{fast}(D') < best_{fit}$}
  		             \STATE $best_v \gets v$
  		             \STATE $best_{fit} \gets new_{fit}$	              
  		             \STATE $improved \gets True$
  		       \ENDIF
  		        \IF{\emph{improved}}
  		      		 \STATE $D_{best} \gets D_{best} \setminus \{best_v\}$
  		       \ENDIF
  		       
  		    \ENDFOR
  		\ENDWHILE
  		\STATE return $D_{best}$
  	\end{algorithmic}
\end{algorithm}
\end{comment}


Our LS procedure consists of two phases. In the first phase, the vertices are added to achieve feasibility -- when the solution is not feasible. In the second phase, the vertices are removed to improve the objective function. The removal is done in a way that does not affect the feasibility previously achieved. 
In both phases, the best improvement strategy is used. This means that all eligible vertices are checked for inclusion/exclusion and then the best vertex is included/excluded. 
Each phase ends with the first iteration where no improvement in fitness is found.  

\begin{comment}
    \emph{Fast fitness evaluation}. Computing the fitness function (\ref{eq:fitness}) takes $O(|E|)$ time -- the most time consuming part is computing the $\emph{violations}(\cdot)$  function. For dense graphs, this complexity can go up to $O(|V|^2)$. Since local search makes many fitness function calls it is too costly to compute the fitness function from scratch every time. In order to execute \texttt{LocalSearch} procedure  efficiently, fast calculations of the fitness function are applied. Before LS enters the first \texttt{while} loop, $C(D_{best}, v), \forall v \in V$ for given solution $D_{best}$ are computed and saved. During vertex addition, that is  $D' = D_{best} \cup \{v\} $, $violations(D')$ is calculated in the following way: 

\begin{multline}
violations(D') = violations(D_{best}) \\
- (k-C(D_{best}, v))  \texttt{I}_{(C(D_{best},v)<k)}  \\ 
- \sum_{w\in N(v) \setminus D_{best}} \texttt{I}_{(C(D_{best}, w)<k)}
\end{multline}

where \texttt{I} stands for the indicator function. 

The part $-(k- C(D_{best}, v)) \texttt{I}_{(C(D_{best},v)<k)}$ adjusts for the effect of the added vertex $v$, i.e., if $v$ was previously \emph{satisfied} before (satisfied the $k$-domination condition), then this indicator function takes the value zero, so nothing changes. This is true because $v$ remains satisfied -- it is now part of $k$-dominating set. 
Otherwise, if vertex $v$ has previously violated the $k$-domination condition, the total violations are reduced by the previous degree of vertex $v$ violation, i.e. $(k- C(D_{best}, v))$.

The part $- \sum_{w\in N(v) \setminus D_{best}} \texttt{I}_{(C(D_{best}, w)<k)}$ adjust for the effect on the vertex $v$ neighbors, which were not in the $k$-dominating set $D_{best}$, i.e. $W=N(v) \setminus D_{best}$. If some of these vertices $w \in W$ violated $k$-domination condition, adding the adjacent vertex $v$ to the solution reduces the total violations. Otherwise, if a vertex $w$ was satisfied, adding $v$ to the solution does not change anything.  
 
In case of a vertex removal, the similar idea is used. 
\end{comment}


\section{Experimental evaluation}\label{sec:experiments}

In this section we analyze the quality of the proposed \textsc{Vns} method.\footnote{\textcolor{red}{All instances, source codes of the \textsc{Vns} and grid search tuning algorithms, and detailed experimental results are publicly available on the GitHub page of this work: \\\url{https://github.com/mikiMilan/k-domination}}.} For this purpose, we include the competing heuristic approaches from the literature. The following four methods for MkDP are compared:  
 ($i$) The standard greedy method from~\cite{parekh1991analysis,gagarin2013randomized}, denoted by SG; ($ii$) Greedy method from~\cite{gagarin2018multiple}, denoted by PG; ($iii$) Beam search approach from~\cite{corcoran2021heuristics}, denoted by BS; ($iv$) \textsc{Vns} approach, as described in Section~\ref{sec:vns}, denoted by \textsc{Vns} .  
 


\emph{Benchmark instances}. For comparison, we consider the benchmark introduced in~\cite{corcoran2021heuristics}. It consists of 20 small to medium sized instances, where all instances represent road networks of different cities modeled through reachability graphs. In addition to these, the authors have provided the program that generate road networks for five large cities: \texttt{Belgrade}, \texttt{Berlin}, \texttt{Boston}, \texttt{Dublin}, and \texttt{Minsk}. Since the road networks \textcolor{red}{of large cities change} over time, the obtained graphs do not fully match those used in the \cite{corcoran2021heuristics}

%, so their properties are given in %Table~\ref{tab:big_instances_chars}.  

\begin{comment}
    \begin{table}
 	\caption{Large-sized instance characteristics.}
 	\label{tab:big_instances_chars}  
 	\begin{tabular}{lrr}
 		City      & $|V|$ & $|E|$ \\ \hline
 		Belgrade      & 19,586 & 7,561,185  \\ 
 		Berlin        & 29,461 & 9,944,851 \\
 	    Boston        & 44,797 & 28,164,740 \\
 	    Dublin        & 37,982 & 21,630,466 \\
 	    Minsk         & 10,487 & 1,375,618 \\ \hline
 	\end{tabular}
 \end{table}
 
 
  \begin{table}
 	\caption{Small to medium sized instances characteristics.}
 	\label{tab:small_instances_chars}  
 	\begin{tabular}{lrr|lrr}
 		City      & $|V|$ & $|E|$ 			& City     & $|V|$ & $|E|$ \\ \hline
 		Bath&910&18560&Liverpool&1273&42564\\
 		Belfast&1700&62617&Manchester&1991&77286\\
 		Brighton&976&35012&Newcastle&1109&26614\\
 		Bristol&1569&47522&Nottingham&1739&51595\\
 		Cardiff&1127&23155&Oxford&479&8396\\
 		Coventry&1175&26689&Plymouth&1122&35070\\
 		Exeter&1250&31997&Sheffield&1582&50534\\
 		Glasgow&1137&24323&Southampton&796&19942\\
 		Leeds&1647&56511&Sunderland&1346&42013\\
 		Leicester&1531&48219&York&1044&23774\\
 		
 		\hline
 	\end{tabular}
 \end{table}
 
\end{comment}

 
 The characteristics of 20 small to medium sized instances can be found in~\cite{corcoran2021heuristics}.
 Unlike the five large networks, these 20 instances are the same as in ~\cite{corcoran2021heuristics} -- we obtained them directly from the authors.

%\textcolor{red}{Table~\ref{tab:small_instances_chars} show the number %of vertices and edges of these instances.}  
\begin{comment}
	content...

\pgfplotstableread{ % Read the data into a table macro
    CityName	|V|
    Manchester	1991
    Nottingham	1739
    Belfast	1700
    Leeds	1647
    Sheffield	1582
    Bristol	1569
    Leicester	1531
    Sunderland	1346
    Liverpool	1273
    Exeter	1250
    Coventry	1175
    Glasgow	1137
    Cardiff	1123
    Plymouth	1122
    Newcastle	1109
    York	1044
    Brighton	976
    Bath	910
    Southampton	796
    Oxford  479
}\testdata


\begin{figure}
	\begin{tikzpicture}
		\begin{axis}[
			legend style={legend columns=1,at={(1,1)},anchor=north east},
			xbar stacked,   % Stacked horizontal bars
			bar width=5pt,
			height=250pt,
			width=0.45\textwidth,
			ytick=data,     % Use as many tick labels as y coordinates
			yticklabels from table={\testdata}{CityName}  % Get the labels from the Label column of the \datatable
			]
            \addplot [fill=cyan!20!green!40] table [x=|V|, meta=CityName,y expr=\coordindex] {\testdata};   % "First" column against the data index
            \legend{No. vertices}
		\end{axis}
	\end{tikzpicture}
	\caption{The number of vertices in the small to medium sized instances.}
	\label{fig:novertex}
\end{figure}

\pgfplotstableread{ % Read the data into a table macro
    CityName	|E|
    Manchester	77286
    Belfast	62617
    Leeds	56511
    Nottingham	51595
    Sheffield	50534
    Leicester	48219
    Bristol	47522
    Liverpool	42564
    Sunderland	42013
    Plymouth	35070
    Brighton	35012
    Exeter	31997
    Coventry	26689
    Newcastle	26614
    Glasgow	24323
    York	23774
    Cardiff	23057
    Southampton	19942
    Bath	18560
    Oxford	8396
}\testdata


\begin{figure}
	\begin{tikzpicture}
		\begin{axis}[
			legend style={legend columns=1,at={(1,1)},anchor=north east},
			xbar stacked,   % Stacked horizontal bars
			bar width=5pt,
			height=250pt,
			width=0.45\textwidth,
			ytick=data,     % Use as many tick labels as y coordinates
			yticklabels from table={\testdata}{CityName}  % Get the labels from the Label column of the \datatable
			]
            \addplot [fill=cyan!20!green!40] table [x=|E|, meta=CityName,y expr=\coordindex] {\testdata};   % "First" column against the data index
            \legend{No. edges}
		\end{axis}
	\end{tikzpicture}
	\caption{The number of edges in the small to medium sized instances.}
	\label{fig:noedges}
\end{figure}
\end{comment}}
 
 \emph{Testing environment}. Experiments were performed on a computer running \textcolor{red}{Intel(R) Core(TM) i5-8265U CPU  1.80GHz with 16GB RAM}, under Microsoft Windows 11 Pro OS. \textsc{Vns} is implemented in Python 3.9. The results of SG, PG and BS for small to medium sized instances are taken from~\cite{corcoran2021heuristics}, reported in their experimental section. Results for the five large instances were obtained by running the original implementation of PG (obtained from the authors). According to the same authors, BS was inefficient for the large instances due to its high computational complexity. Therefore, we did not include it in the large instance comparison.  
 PG and \textsc{Vns} algorithms are run ten times (using different random seeds) per each problem instance. 
   
  The termination criteria of the \textsc{Vns} are: ($i$) the maximum running time of 30~minutes, and ($ii$) the maximum number of 20000 iterations. The time limit of 30~minutes is not checked during initialization (line~\ref{vns:init} in Algorithm~\ref{alg:vns}). It means that \textsc{Vns} can take more than 30~minutes to finish for some very large instances, such as \texttt{Dublin} and \texttt{Boston}. More precisely, in these situations, after initialization, the most important steps of \textsc{Vns} (shaking and subsequent local search) are not even performed due to an expired time limit.
  
  \textcolor{red}{The termination criteria were chosen in a way that allows similar running times to those reported by comparison algorithms ~\cite{corcoran2021heuristics}. Namely, the best results were obtained with the BS configuration BS4, where 4 stands for the beam width. For this algorithm, in the case of $k=2$, the average running times in seconds are 1736, 8834, 1257, 7156 and 3327 for the Bath, Belfast, Brighton, Bristol and Cardiff instances, respectively.} \textcolor{red}{As stated in ~\cite{corcoran2021heuristics}, the comparison algorithms were also implemented in  Python and executed on a desktop computer with an Intel Core i7-8700 CPU @3.20GHz. The algorithms SG, PG and BS terminate their execution as soon as the first feasible solution is reached.}
   

   \textcolor{red}{\emph{Parameters tuning}. As mentioned earlier, \textsc{Vns} for MkDPA involves four control parameters: $d_{min}, d_{max}, p_{move}$ and \emph{penalty}. We decided to use on a simple method of tuning the parameters, that is, a grid search. As recommended in  ~\cite{mladenovic1997variable}, we fixed the parameter $d_{min}$ with a value 1. The sets of parameters used for tuning are:}
  $d_{max}\in{\left\lbrace 5, 10, 15, 20, 25, 30, 40, 50, 100\right\rbrace }$,  $p_{move}\in{\left\lbrace 0, 0.25, 0.5, 0.75, 1\right\rbrace }$, and $penalty\in{\left\lbrace 0.005, 0.01, 0.015, 0.02\right\rbrace }$. \textcolor{red}{A sample of 20 instances for grid search by width was chosen randomly from the set of small and medium instances and for  $k\in \{1, 2, 4\}$. A grid search by height was performed on a set of 180 configurations. For each instance and each configuration, the value of the fitness function was calculated. \textsc{Vns} was limited to 100 iterations. The best configuration   was obtained using the rank method and is as follows: $(d_{max}, p_{move}, penalty )=(50,0.5, 0.005)$.}

\subsection{Experimental results }
{ \color{red} Table~\ref{tab:k124} contains the results for $k \in \{1, 2,4\}$.  The first column gives the name of the instance (city) for which the results are reported. The next block contains   instance size information. Next three blocks report the results in case of $k=1,2,4$ for \textsc{Vns} and the best results so-far from literature, respectively.  More in details, each of these (three) blocks consists of 6 columns. The first three columns show the results of \textsc{Vns}: average solution quality ($\overline{|D|}$), standard deviation ($\sigma(|D|)$) and average running time ($\overline{t}$).  The other three columns report  the results of the best approach from the literature:   name of the approach,  the best obtained  result ($\overline{|D|}$) and average solution quality over ten runs ($\overline{t}$).  Note that   labels BS1, BS2 or BS4 correspond to BS approach with beam widths of 1,2 and 4, respectively. } The following conclusions can be drawn from these results. 
   
\begin{itemize}
  		\item  For $k=1$, \textsc{Vns} outperformed all competing approaches for small to medium sized instances. \textsc{Vns} also outperformed the PG approach for the large-sized instances. {\color{red}The same holds for the large-sized instances. }
  		\item Concerning the results for $k=2$, \textsc{Vns} outperformed all competing approaches by nearly 15\% in terms of the average solution quality. Similar conclusions hold for the large instances: \textsc{Vns} produces $\approx$ 5--16\% improvement rate over the second best, PG approach. 
  		\item The similar {\color{red}conclusions are drawn} for $k=4$. \textsc{Vns} outperforms the second-best algorithm by more than 15\% in some cases (see, for example,  the instance \texttt{Nottingham} where \textsc{Vns} achieved a score 164.2 over BS4 which achieved a score 195.2). For the large instances, \textsc{Vns}   outperforms PG in all cases. 
  		\item {\color{red} The average times (in seconds) of \textsc{Vns}  range from 46 seconds for $k=1$ and a small-sized instance (\texttt{Cardiff}) to 3819 seconds for $k=4$ and a large-size instance (\texttt{Boston}).
         Clearly as $k$ grows, the average times of \textsc{Vns} increase rapidly. In case of the instances size growth, similar behavior of the average times can be noticed. }
\end{itemize}

 
   \begin{table*}[!htb]
	\tiny
 	\caption{Results}
 	\label{tab:k124}      %\scalebox{0.7}{
 	\begin{tabular}{l|rr|rrr|rlr|rrr|rlr|rrr|rlr}
 		\hline
 		\multicolumn{1}{c|}{ } & \multicolumn{2}{c|}{Instance size} & \multicolumn{6}{c|}{ Results for $k=1$ } & \multicolumn{6}{c|}{ Results for $k=2$ } & \multicolumn{6}{c}{ Results for $k=4$ }\\ 
 		\hline
 		\emph{City} & $|V|$ & $|E|$ & $\overline{|D|}$ & $\sigma(|D|)$& $\overline{t}$ & Alg. & $\overline{|D|}$ & $\sigma(|D|)$ & $\overline{|D|}$ & $\sigma(|D|)$ & $\overline{t}$& Alg. & $\overline{|D|}$& $\sigma(|D|)$ & Avg. & $\sigma(|D|)$ & $\overline{t}$& Alg. & $\overline{|D|}$ & $\sigma(|D|)$ \\ \hline
 		Belfast&1700&62617&\bf{39}&0&91&BS4&50.2&1.5&\bf{76.3}&0.5&817.5&BS4&97.6&1&\bf{148.3}&0.7&1158.7&BS4&179.6&2\\
 		Brighton&976&35012&\bf{21}&0&203.5&BS4&28.2&0.6&\bf{40.1}&0.3&586.6&BS4&49.4&0.5&\bf{78}&0.5&768.2&BS4&94.8&1.9\\
 		Bristol&1569&47522&\bf{37}&0&75.6&BS2&47.4&1&\bf{73.8}&0.4&486.5&BS4&94&1.4&\bf{146.6}&1.1&1003.2&BS4&176.4&0.8\\
 		Cardiff&1127&23155&\bf{39}&0&46.2&BS4&50.6&1&\bf{78.3}&0.5&345.7&BS4&95.6&1.6&\bf{157.5}&0.8&328.3&BS4&183.2&1.4\\
 		Coventry&1175&26689&\bf{38}&0&341.3&BS4&44.8&0.4&\bf{73}&0&280.3&BS4&85.1&0.7&\bf{149.2}&0.9&333.1&BS4&172.6&1.4\\
 		Exeter&1250&31997&\bf{38}&0&56.9&BS4&50.6&0.5&\bf{77}&0&370.2&BS4&95.7&1&\bf{158.1}&0.7&573.9&BS4&182.3&0.6\\
 		Glasgow&1137&24323&\bf{50.1}&0.3&310.5&BS4&59.2&0.7&\bf{94}&0.5&236.1&BS4&110.6&1.7&\bf{175.2}&0.9&474.5&BS4&199.8&1.6\\
 		Leeds&1647&56511&\bf{40}&0&290.4&BS4&52.4&0.8&\bf{79.5}&0.5&1032.2&BS4&99.6&1&\bf{152.8}&0.8&939.3&BS4&187.1&0.7\\
 		Leicester&1531&48219&\bf{38}&0&205.5&BS4&51.5&0.5&\bf{75}&0&586.1&BS4&94.1&0.8&\bf{149.3}&0.7&1033.3&BS4&177.7&1.8\\
 		Liverpool&1273&42564&\bf{28}&0&443.8&BS4&38.4&0.5&\bf{57}&0.5&393.8&BS4&72&0.8&\bf{112.8}&0.6&845.5&BS4&133&0.8\\
 		Manchester&1991&77286&\bf{38.3}&0.7&617.7&BS4&45.9&0.5&\bf{77.9}&0.3&994.5&BS4&91.5&0.9&\bf{155.2}&0.6&1446.7&BS4&178.5&1\\
 		Newcastle&1109&26614&\bf{44}&0&222.4&BS4&52.6&1.1&\bf{83.6}&0.5&506&BS4&95.4&1.1&\bf{152.4}&0.5&626.3&BS2&171.5&1.2\\
 		Nottingham&1739&51595&\bf{44}&0&80.7&BS4&56.6&0.8&\bf{84.7}&0.5&1218.7&BS4&103.3&0.8&\bf{164.2}&0.8&993.7&BS4&195.2&1.2\\
 		Oxford&479&8396&\bf{24}&0&42.8&BS4&27.9&0.5&\bf{47}&0&8.3&BS4&54.9&0.7&\bf{89}&0&70.5&BS2&100.8&0.9\\
 		Plymouth&1122&35070&\bf{31}&0&44.6&BS4&40.3&0.8&\bf{61.3}&0.5&767.7&BS4&75&1.1&\bf{115.6}&0.5&643.1&BS4&137&1.2\\
 		Sheffield&1582&50534&\bf{42}&0&118&BS4&52.5&0.7&\bf{84.6}&0.5&523.3&BS4&98.9&1.3&\bf{161.4}&0.8&1047.1&BS4&182.2&1.2\\
 		Southampton&796&19942&\bf{25}&0&7.4&BS4&29.6&0.8&\bf{49.2}&0.4&311.1&BS4&61.1&0.7&\bf{97.6}&0.5&289.2&BS4&113.2&1.4\\
 		Sunderland&1346&42013&\bf{36}&0&88.1&BS4&46.3&0.4&\bf{73}&0&211.4&BS4&89.1&1.1&\bf{141}&0.5&840.9&BS4&163.6&1\\
 		York&1044&23774&\bf{32}&0&35.8&BS4&39.1&0.3&\bf{68}&0&26.2&BS4&77.6&0.6&\bf{130.4}&0.5&250.3&BS4&145.8&1.2\\
 		Belgrade&19586&7561185&\bf{86.5}&1.5&1493.9&PG&103.4&0.5&\bf{171.1}&2.4&1564&PG&197.3&0.9&\bf{341.9}&2.2&1680.7&SG&374.5&1.4\\
 		Berlin&29461&9944851&\bf{102.1}&1.9&2056.6&PG&125.9&0.5&\bf{204.9}&1.9&1309&PG&240.1&1.2&\bf{396.4}&3.1&1763.4&PG&446.2&1.8\\
 		Boston&44797&28164740&\bf{94.3}&1.9&1408.3&PG&102.7&1.3&\bf{175.4}&2&1445.8&PG&191.6&0.9&\bf{341}&0&3819.2&PG&368.7&1.5\\
 		Dublin&37982&21630466&\bf{101.5}&1.1&1437.8&PG&113.8&1.2&\bf{193.2}&4.8&1705&PG&211.3&2.7&\bf{363}&0&3002.4&PG&390.2&2\\
 		Minsk&10487&1375618&\bf{102.1}&1.1&1293.9&PG&126&0.9&\bf{200}&1.9&1517.4&PG&240.4&1.4&\bf{387.7}&3.5&1636.5&PG&457.6&2.4\\
 		\hline
 				
 	\end{tabular}%}
 \end{table*}
 
 

%(see Table~\ref{tab:big_instances_chars}).  

\begin{comment}
    
\pgfplotstableread{ % Read the data into a table macro
	City	k1	k2	k4
	Manchester	844.078	1608.695	2584.787
	Nottingham	85.132	1125.304	1827.64
	Belfast	66.681	865.443	1800.359
	Sunderland	44.395	187.461	2464.102
	Leicester	233.02	462.418	1729.272
	Newcastle	88.577	378.578	1147.646
	Leeds	132.67	291.423	1078.052
	Liverpool	192.537	239.716	981.006
	Bristol	129.058	571.793	638.25
	Coventry	144.585	300.407	826.953
	Brighton	89.172	292.017	858.973
	Sheffield	78.21	289.042	850.464
	Plymouth	55.003	205.265	919.927
	Cardiff	41.944	181.9	679.325
	Exeter	52.443	285.106	387.588
	Bath	60.934	256.686	285.744
	Glasgow	90.929	110.067	376.057
	York	28.401	111.923	359.89
	Southampton	7.778	147.781	203.324
	Oxford	18.758	6.93	23.79
}\testdata

\begin{figure}
	\begin{tikzpicture}
		\begin{axis}[
			legend style={legend columns=1,at={(1,1)},anchor=north east},
			xbar stacked,   % Stacked horizontal bars
			bar width=5pt,
			ytick=data,     % Use as many tick labels as y coordinates
			yticklabels from table={\testdata}{City}  % Get the labels from the Label column of the \datatable
			]
			\addplot [fill=cyan!20!green!40] table [x=k1, meta=City,y expr=\coordindex] {\testdata};   % "First" column against the data index
			\addplot [fill=cyan!60!green!20] table [x=k2, meta=City,y expr=\coordindex] {\testdata};
			\addplot [fill=cyan!10] table [x=k4, meta=City,y expr=\coordindex] {\testdata};
			\legend{k=1, k=2,k=4}
		\end{axis}
	\end{tikzpicture}
	\caption{Average times (in seconds) of finding the best solution for small to medium sized instances.}
	\label{fig:timeSmall}  
\end{figure}

\end{comment}

 
\section{Conclusions and future work}

 
 In this paper we have studied the $k$-domination problem, $k \in \mathbb{N}$,  a generalized version of the prominent minimum dominating set problem. This problem has been solved so far by several constructive and incremental approaches. We proposed the variable neighborhood search (VNS) metaheuristic to solve this problem. It is equipped with an effective fitness function that evaluates both feasible and infeasible solutions. Moreover, an efficient local search procedure with best-improvement strategy and fast fitness function evaluation plays an important role in obtaining high-quality solutions. The efficiency of our \textsc{Vns} has been validated on the real-world benchmark, where it has been shown that \textsc{Vns} outperform all existing heuristic state-of-the-art approaches. 
 
 For future work, one could consider improving the \textsc{Vns} to work more efficiently with very large graphs, such as social networks.  \textsc{Vns} could be compared to exact approaches such as integer linear programming models, solved by {\color{red} general-purpose solvers}, i.e.  Cplex or Gurobi. 
  
\section*{Acknowledgments} 
We thank Padraig Corcoran and Andrei Gagarin for providing problem instances and their algorithm implementations.  
\textcolor{red}{A.~Kartelj was supported by grant 451-03-47/2023-01/200104 funded by Ministry of Science Technological Development and Innovations of the Republic of Serbia.}
%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{gecco_2023}

%%
%% If your work has an appendix, this is the place to put it.
%\appendix
 
\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
